#need to run Data Prep code first. 

library(tidyverse)
library(dplyr)
library(ggplot2)
library(randomForest) 
library(permimp)
library(party)
library(readxl)
library(writexl)
library(pdp)
library(factoextra)
library(gridExtra)
library(standardize)
library(ggpubr)
library(beepr)

#########CYP 1A1 intestine############## 
# Pull out relevant columns
names(CYP1A1.intestine)
cyp_1a1_int_sub <- CYP1A1.intestine[,c(2:41)]
cyp_1a1_int_sub[,1] <- round(cyp_1a1_int_sub[,1], 2)
View(cyp_1a1_int_sub)

p <-ncol(cyp_1a1_int_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=cyp_1a1_int_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((cyp_1a1_int_sub$Effect-cf.pred)^2)) # 12.86119
mean(abs(cyp_1a1_int_sub$Effect-cf.pred)) # 9.157176

# Plot predicted vs. observed
plot(y=cf.pred, x=cyp_1a1_int_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional

# cf.cpi$perTree # VI values per tree
plot(cf.cpi, type="bar")

### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
cyp_int_preds <- CYP1A1.intestine[, c(2:41)] # original predictors
cyp_int_preds[,1] <- round(cyp_int_preds[,1], 2)
cyp_int_preds_loop <- cyp_int_preds 
View(cyp_int_preds_loop)

p <- ncol(cyp_int_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

#run RF - conditional
set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(cyp_int_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=cyp_int_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((cyp_int_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(cyp_int_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((cyp_int_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(cyp_int_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  cyp_int_preds_loop <- cyp_int_preds_loop[,!colnames(cyp_int_preds_loop)==var.list[i]] # remove variable
  
}
beep()

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)

# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse)) #39
which(OOB.mae==min(OOB.mae)) #37

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]
#pyrene#

#double check with rounded error#
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #39
which(OOB.mae_1==min(OOB.mae_1)) #39

var.list[which(OOB.mae_1==min(OOB.mae_1)):length(OOB.mae_1)]

#same! rock & roll#

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90_cyp1a1_intestine.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90_cyp1a1_intestine.csv", row.names = FALSE)

#set mtry = # of predictors left in model / 3 (nump/3) - and round it up to solid number 
# Refit final model
cyp_int_final <- CYP1A1.intestine %>% dplyr::select(Effect, Pyrene)

set.seed(3)
cf.final <- cforest(Effect~., data=cyp_int_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
cyp_int_final_wPred <- cbind(cyp_int_final, cf.final.pred.oob)
# OOB error
mean(abs(CYP1A1.intestine$Effect-cf.final.pred.oob$Predicted_OOB)) #8.637239
sqrt(mean((cyp_int_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) #12.5258

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=cyp_int_final_wPred, pch=16)
abline(a=0, b=1)

# Single variable partial dependence plots
cyp1a1_int_pd_pyrene <- partial(cf.final, pred.var="Pyrene", grid.resolution = 10)
cyp1a1_int_pdp_pyrene <- autoplot(cyp1a1_int_pd_pyrene, size=1.2) + theme_classic() + xlab("Pyrene") + ylab("Effect") +
  theme(text=element_text(size=20))

cyp1a1_intestine <- grid.arrange(cyp1a1_int_pdp_pyrene)
ggsave("CYP1A1_intestine.jpeg", cyp1a1_intestine)

###CYP1a1_intestine - unconditional####
cyp_int_preds <- CYP1A1.intestine[, c(2:48)] # original predictors
cyp_int_preds[,1] <- round(cyp_int_preds[,1], 2)
cyp_int_preds_loop <- cyp_int_preds 
View(cyp_int_preds_loop)

p <- ncol(cyp_int_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(cyp_int_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=cyp_int_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((cyp_int_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(cyp_int_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((cyp_int_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(cyp_int_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=1) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  cyp_int_preds_loop <- cyp_int_preds_loop[,!colnames(cyp_int_preds_loop)==var.list[i]] # remove variable
  
}
beep()

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)


which(OOB.rmse==min(OOB.rmse)) #43
which(OOB.mae==min(OOB.mae)) #34
var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round 
OOB.rmse_1 <- round(OOB.rmse,2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #43
which(OOB.mae_1==min(OOB.mae_1)) #34
var.list[which(OOB.mae_1==min(OOB.mae_1)):length(OOB.mae_1)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm
saveRDS(VI.list, "cf_VI_at_iter_thresh100_cyp1a1_intestine.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh100_cyp1a1_intestine.csv", row.names = FALSE)

# Refit final model
cyp_int_final <- CYP1A1.intestine %>% dplyr::select(Effect, Hexamethylenetetramine, Isophorone, Fluoranthene, Phenanthrene, Cholesterol, Cotinine, Pyrene, Carbazole, Metformin, Atrazine, `Triphenyl phosphate`, Diltiazem, Anthraquinone)

set.seed(3)
cf.final <- cforest(Effect~., data=cyp_int_final, control=cforest_unbiased(mtry=8, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
cyp_int_final_wPred <- cbind(cyp_int_final, cf.final.pred.oob)

# OOB error
mean(abs(CYP1A1.intestine$Effect-cf.final.pred.oob$Predicted_OOB))#8.708865
sqrt(mean((cyp_int_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) #12.65426

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=cyp_int_final_wPred, pch=16)
abline(a=0, b=1)

#################CYP 1A1 liver ########### 
# Pull out relevant columns
names(cyp_1a1_2017_liver)
cyp_1a1_liv_sub <- cyp_1a1_2017_liver[,c(2:41)]
cyp_1a1_liv_sub[,1] <- round(cyp_1a1_liv_sub[,1], 2)
View(cyp_1a1_liv_sub)

p <-ncol(cyp_1a1_liv_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=cyp_1a1_liv_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((cyp_1a1_liv_sub$Effect-cf.pred)^2))# 2.253351
mean(abs(cyp_1a1_liv_sub$Effect-cf.pred))#1.229144

# Plot predicted vs. observed
plot(y=cf.pred, x=cyp_1a1_liv_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional

# cf.cpi$perTree # VI values per tree
plot(cf.cpi, type="bar")

### Loop to recursively eliminate least informative variables ####
cyp_liv_preds <- cyp_1a1_2017_liver[, c(2:41)] # original predictors
cyp_liv_preds[,1] <- round(cyp_liv_preds[,1], 2)
cyp_liv_preds_loop <- cyp_liv_preds 

p <- ncol(cyp_liv_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
nump <- ncol(cyp_liv_preds_loop)-1 # Number predictors
  
set.seed(3) 
cf <- cforest(Effect~., data=cyp_liv_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
cf.pred <- predict(cf, OOB=T)
cf.pred.tr <- predict(cf, OOB=F)
  
# OOB error
OOB.rmse[i] <- sqrt(mean((cyp_liv_preds$Effect-cf.pred)^2)) # OOB rmse
OOB.mae[i] <- mean(abs(cyp_liv_preds$Effect-cf.pred)) # oob mae
  
# Training error
train.rmse[i] <- sqrt(mean((cyp_liv_preds$Effect-cf.pred.tr)^2)) # training rmse
train.mae[i] <- mean(abs(cyp_liv_preds$Effect-cf.pred.tr)) #  training mae
  
  
# Variable importance
set.seed(3) 
cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.90) # set threshold to 1 for unconditional
  
VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
cyp_liv_preds_loop <- cyp_liv_preds_loop[,!colnames(cyp_liv_preds_loop)==var.list[i]] # remove variable
  
}
beep()

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)

plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)

# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse)) #39
which(OOB.mae==min(OOB.mae)) #11

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#double check with rounded error#
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #39
which(OOB.mae_1==min(OOB.mae_1)) #18

# [1] "Bisphenol A"                       "Metformin"                         "3,4-Dichlorophenyl isocyanate"    
# [4] "Carbamazepine"                     "Caffeine"                          "Lidocaine"                        
# [7] "Carbaryl"                          "5-Methyl-1H-benzotriazole"         "Isophorone"                       
# [10] "4-tert-Octylphenol monoethoxylate" "N,N-diethyl-meta-toluamide"        "1-Methylnaphthalene"              
# [13] "Cotinine"                          "Desvenlafaxine"                    "Acetaminophen"                    
# [16] "Pyrene"                            "Methyl-1H-benzotriazole"           "Benzo[a]pyrene"                   
# [19] "Fluoranthene"                      "Carbazole"                         "Anthraquinone"                    
# [22] "Phenanthrene"         

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#different - go with the rounded & least variabled #

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90.cyp1a12017liv.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.cyp1a12017liv.csv", row.names = FALSE)

# Refit final model
cyp_liv_final <- cyp_1a1_2017_liver %>% dplyr::select(Effect, Anthraquinone, Phenanthrene, Carbazole,
                                                      Fluoranthene, "Benzo[a]pyrene", "Methyl-1H-benzotriazole",
                                                      Pyrene, Acetaminophen, Desvenlafaxine, Cotinine, 
                                                      "1-Methylnaphthalene", "N,N-diethyl-meta-toluamide", "4-tert-Octylphenol monoethoxylate",
                                                      Isophorone, "5-Methyl-1H-benzotriazole", Carbaryl, Lidocaine, Caffeine, 
                                                      Carbamazepine, "3,4-Dichlorophenyl isocyanate", Metformin, "Bisphenol A") 

set.seed(3)
cf.final <- cforest(Effect~., data=cyp_liv_final, control=cforest_unbiased(mtry=7, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
cyp_liv_final_wPred <- cbind(cyp_liv_final, cf.final.pred.oob)

# OOB error
mean(abs(cyp_1a1_2017_liver$Effect-cf.final.pred.oob$Predicted_OOB)) #1.201025
sqrt(mean((cyp_liv_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) #2.185432

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=cyp_liv_final_wPred, pch=16)
abline(a=0, b=1)


### Loop to recursively eliminate least informative variables - unconditional ####
cyp_liv_preds <- cyp_1a1_2017_liver[, c(2:4)] # original predictors
cyp_liv_preds[,1] <- round(cyp_liv_preds[,1], 2)
cyp_liv_preds_loop <- cyp_liv_preds 
View(cyp_liv_preds_loop)

p <- ncol(cyp_liv_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(cyp_liv_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=cyp_liv_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((cyp_liv_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(cyp_liv_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((cyp_liv_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(cyp_liv_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=1.0) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  cyp_liv_preds_loop <- cyp_liv_preds_loop[,!colnames(cyp_liv_preds_loop)==var.list[i]] # remove variable
  
}
beep(8)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)

plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)

# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse)) #45
which(OOB.mae==min(OOB.mae)) #32
var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh100.cyp1a12017liv.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh100.cyp1a12017liv.csv", row.names = FALSE)

#double check with rounded error#
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #45
which(OOB.mae_1==min(OOB.mae_1)) #45

# Refit final model
cyp_liv_final <- cyp_1a1_2017_liver %>% dplyr::select(Effect, Anthraquinone, Phenanthrene)

set.seed(3)
cf.final <- cforest(Effect~., data=cyp_liv_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
cyp_liv_final_wPred <- cbind(cyp_liv_final, cf.final.pred.oob)

# OOB error
mean(abs(cyp_1a1_2017_liver$Effect-cf.final.pred.oob$Predicted_OOB))#1.201025
sqrt(mean((cyp_liv_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2))#2.185432

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=cyp_liv_final_wPred, pch=16)
abline(a=0, b=1)

#################CYP 1A1 liver 2018 ########### 
# Pull out relevant columns
names(cyp1a1_2018)
cyp_1a1_2018_sub <- cyp1a1_2018[,c(2:72)]
cyp_1a1_2018_sub[,1] <- round(cyp_1a1_2018_sub[,1], 2)
View(cyp_1a1_2018_sub)

p <-ncol(cyp_1a1_2018_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=cyp_1a1_2018_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)

sqrt(mean((cyp_1a1_2018_sub$Effect-cf.pred)^2)) #3.227891
mean(abs(cyp_1a1_2018_sub$Effect-cf.pred)) #1.7706

# Plot predicted vs. observed
plot(y=cf.pred, x=cyp_1a1_2018_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional

# cf.cpi$perTree # VI values per tree
plot(cf.cpi, type="bar")

### Loop to recursively eliminate least informative variables ####
cyp_1a1_2018_preds <- cyp1a1_2018[, c(2:72)] # original predictors
cyp_1a1_2018_preds[,1] <- round(cyp_1a1_2018_preds[,1], 2)
cyp_1a1_2018_preds_loop <- cyp_1a1_2018_preds 

p <- ncol(cyp_1a1_2018_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(cyp_1a1_2018_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=cyp_1a1_2018_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((cyp_1a1_2018_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(cyp_1a1_2018_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((cyp_1a1_2018_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(cyp_1a1_2018_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.90) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  cyp_1a1_2018_preds_loop <- cyp_1a1_2018_preds_loop[,!colnames(cyp_1a1_2018_preds_loop)==var.list[i]] # remove variable
  
}
beep(8)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)

# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse)) #56
which(OOB.mae==min(OOB.mae)) #49

var.list[max(which(OOB.mae==min(OOB.mae))):length(OOB.mae)]

#double check with rounded error#
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #56
which(OOB.mae_1==min(OOB.mae_1)) #49

var.list[which(OOB.mae_1==min(OOB.mae_1)):length(OOB.mae_1)]


# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90.cyp1a1.2018.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.cyp1a1.2018.csv", row.names = FALSE)


# Refit final model
cyp_1a1_2018_final <- cyp1a1_2018 %>% dplyr::select(Effect,Pyrene, Triamterene, Ranitidine,
                                                     Venlafaxine, "beta-Sitosterol", Metformin, 
                                                    Metolachlor,"1-Methylnaphthalene",  Dextromethorphan,
                                                    Fluoranthene, Atrazine,Metoprolol,
                                                    "N,N-diethyl-meta-toluamide", Anthraquinone,`Benzo[a]pyrene`, 
                                                    Acetaminophen, Cholesterol, Phenanthrene, Cotinine, Caffeine,
                                                    `Tributyl phosphate`, `Methyl-1H-benzotriazole`)

set.seed(3)
cf.final <- cforest(Effect~., data=cyp_1a1_2018_final, control=cforest_unbiased(mtry=7, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
cyp_1a1_2018_final_wPred <- cbind(cyp_1a1_2018_final, cf.final.pred.oob)

# OOB error
mean(abs(cyp1a1_2018$Effect-cf.final.pred.oob$Predicted_OOB)) #1.761411
sqrt(mean((cyp_1a1_2018_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) #3.229624

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=cyp_1a1_2018_final_wPred, pch=16)
abline(a=0, b=1)

##unconditional CYP 1A1 liver 2018####
# Pull out response and predictors - columns 5, 7-58
names(cyp1a1_2018)
cyp_1a1_2018_preds <- cyp1a1_2018[, c(2:77)] # original predictors
cyp_1a1_2018_preds[,1] <- round(cyp_1a1_2018_preds[,1], 2)
cyp_1a1_2018_preds_loop <- cyp_1a1_2018_preds 

View(cyp_1a1_2018_preds_loop)
p <- ncol(cyp_1a1_2018_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(cyp_1a1_2018_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=cyp_1a1_2018_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((cyp_1a1_2018_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(cyp_1a1_2018_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((cyp_1a1_2018_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(cyp_1a1_2018_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=1) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  cyp_1a1_2018_preds_loop <- cyp_1a1_2018_preds_loop[,!colnames(cyp_1a1_2018_preds_loop)==var.list[i]] # remove variable
  
}
beep(4)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)


which(OOB.rmse==min(OOB.rmse)) #61
which(OOB.mae==min(OOB.mae)) #21
var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]


#double check with rounded error#
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #61
which(OOB.mae_1==min(OOB.mae_1)) #66

#different - 66#

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh100.cyp1a1.2018.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh100.cyp1a1.2018.csv", row.names = FALSE)


# Refit final model
cyp_1a1_2018_final <- cyp1a1_2018 %>% dplyr::select(Effect, 'Benzo[a]pyrene', Cholesterol, Hexamethylenetetramine, "N,N-diethyl-meta-toluamide", Phenanthrene, Anthraquinone, Acetaminophen, Caffeine, "Tributyl phosphate", "Methyl-1H-benzotriazole")
set.seed(3)
cf.final <- cforest(Effect~., data=cyp_1a1_2018_final, control=cforest_unbiased(mtry=3, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
cyp_1a1_2018_final_wPred <- cbind(cyp_1a1_2018_final, cf.final.pred.oob)

# OOB error
mean(abs(cyp1a1_2018$Effect-cf.final.pred.oob$Predicted_OOB)) #1.771513 
sqrt(mean((cyp_1a1_2018_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) #3.228002

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=cyp_1a1_2018_final_wPred, pch=16)
abline(a=0, b=1)


#################CYP 3A liver 2017 ########### 
# Pull out relevant columns
names(cyp_3A_liver)
cyp_3A_liver_sub <- cyp_3A_liver[,c(2:41)]
cyp_3A_liver_sub[,1] <- round(cyp_3A_liver_sub[,1], 2)
p <-ncol(cyp_3A_liver)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=cyp_3A_liver_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((cyp_3A_liver_sub$Effect-cf.pred)^2)) #0.5739888
mean(abs(cyp_3A_liver_sub$Effect-cf.pred)) #0.4579518

# Plot predicted vs. observed
plot(y=cf.pred, x=cyp_3A_liver_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.9, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional

# cf.cpi$perTree # VI values per tree
plot(cf.cpi, type="bar")

### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
cyp_3A_liver_preds <- cyp_3A_liver[, c(2:41)] # original predictors
cyp_3A_liver_preds[,1] <- round(cyp_3A_liver_preds[,1], 2)
cyp_3A_liver_preds_loop <- cyp_3A_liver_preds 

p <- ncol(cyp_3A_liver_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(cyp_3A_liver_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=cyp_3A_liver_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((cyp_3A_liver_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(cyp_3A_liver_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((cyp_3A_liver_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(cyp_3A_liver_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  cyp_3A_liver_preds_loop <- cyp_3A_liver_preds_loop[,!colnames(cyp_3A_liver_preds_loop)==var.list[i]] # remove variable
  
}
beep(7)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#39
which(OOB.mae==min(OOB.mae))#38
var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]
#"Indole"    "Carbazole"

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90.CYP3Aliv.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.CYP3Aliv.csv", row.names = FALSE)

#round
OOB.mae_1 <- round(OOB.mae, 2)
OOB.rmse_1 <- round(OOB.rmse, 2)

which(OOB.mae_1==min(OOB.mae_1))#38
which(OOB.rmse_1==min(OOB.rmse_1))#39
var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#tris(2-chloroethyl)phosphate#

# Refit final model
CYP3A_liv_final <- cyp_3A_liver %>% dplyr::select(Effect, Indole, Carbazole)

set.seed(3)
cf.final <- cforest(Effect~., data=CYP3A_liv_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
CYP3A_liv_final_wPred <- cbind(CYP3A_liv_final, cf.final.pred.oob)

# OOB error
mean(abs(CYP3A_liv_final$Effect-cf.final.pred.oob$Predicted_OOB)) #0.4534382
sqrt(mean((cyp_3A_liver_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2))#0.5645823 

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=CYP3A_liv_final_wPred, pch=16)
abline(a=0, b=1)


### Unconditional analysis ####

# Pull out response and predictors - columns 5, 7-53
cyp_3A_liver_preds <- cyp_3A_liver[, c(2:48)] # original predictors
cyp_3A_liver_preds[,1] <- round(cyp_3A_liver_preds[,1], 2)
cyp_3A_liver_preds_loop <- cyp_3A_liver_preds 

p <- ncol(cyp_3A_liver_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(cyp_3A_liver_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=cyp_3A_liver_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((cyp_3A_liver_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(cyp_3A_liver_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((cyp_3A_liver_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(cyp_3A_liver_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=1.0) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  cyp_3A_liver_preds_loop <- cyp_3A_liver_preds_loop[,!colnames(cyp_3A_liver_preds_loop)==var.list[i]] # remove variable
  
}
beep(8)
# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse)) #46
which(OOB.mae==min(OOB.mae)) #46
var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#check rounding#
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #46
which(OOB.mae_1==min(OOB.mae_1)) #46

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh100.CYP3Aliv.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh100.CYP3Aliv.csv", row.names = FALSE)


# Refit final model
CYP3A_liv_final <- cyp_3A_liver %>% dplyr::select(Effect, `Tris(2-chloroethyl)phosphate`)

set.seed(3)
cf.final <- cforest(Effect~., data=CYP3A_liv_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
CYP3A_liv_final_wPred <- cbind(CYP3A_liv_final, cf.final.pred.oob)

# OOB error
mean(abs(CYP3A_liv_final$Effect-cf.final.pred.oob$Predicted_OOB))#0.4127008
sqrt(mean((cyp_3A_liver_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) #0.5228714 

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=CYP3A_liv_final_wPred, pch=16)
abline(a=0, b=1)


#################CYP 3A intestine 2017 ########### 
# Pull out relevant columns
names(CYP_3A_intestine)
CYP_3A_intestine_sub <- CYP_3A_intestine[,c(2:41)]
CYP_3A_intestine_sub[,1] <- round(CYP_3A_intestine_sub[,1], 2)
p <-ncol(CYP_3A_intestine)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=CYP_3A_intestine_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((CYP_3A_intestine_sub$Effect-cf.pred)^2))# 2.049881
mean(abs(CYP_3A_intestine_sub$Effect-cf.pred)) #1.514496

# Plot predicted vs. observed
plot(y=cf.pred, x=CYP_3A_intestine_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9, can try values between 0.8-1)
set.seed(3) 
#changed threshold to help it permute
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional

# cf.cpi$perTree # VI values per tree
plot(cf.cpi, type="bar")


### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors
CYP_3A_intestine_preds <- CYP_3A_intestine[, c(2:41)] # original predictors
CYP_3A_intestine_preds[,1] <- round(CYP_3A_intestine_preds[,1], 2)
CYP_3A_intestine_preds_loop <- CYP_3A_intestine_preds 

p <- ncol(CYP_3A_intestine_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(CYP_3A_intestine_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=CYP_3A_intestine_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((CYP_3A_intestine_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(CYP_3A_intestine_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((CYP_3A_intestine_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(CYP_3A_intestine_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  CYP_3A_intestine_preds_loop <- CYP_3A_intestine_preds_loop[,!colnames(CYP_3A_intestine_preds_loop)==var.list[i]] # remove variable
  
}
beep(8)
# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)

# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#38
which(OOB.mae==min(OOB.mae))#39

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round it up!#
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1))#39
which(OOB.mae_1==min(OOB.mae_1))#39

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90.CYP3Aint.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)
View(RFE_info)
write.csv(RFE_info, "cf_RFE_info_thresh90.CYP3Aint.csv", row.names = FALSE)


# Refit final model
CYP_3A_intestine_final <- CYP_3A_intestine %>% dplyr::select(Effect, "Methyl-1H-benzotriazole")

set.seed(3)
cf.final <- cforest(Effect~., data=CYP_3A_intestine_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
CYP_3A_intestine_final_wPred <- cbind(CYP_3A_intestine_final, cf.final.pred.oob)

# OOB error
mean(abs(CYP_3A_intestine_final$Effect-cf.final.pred.oob$Predicted_OOB)) ##1.470198
sqrt(mean((CYP_3A_intestine_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) # 2.039119 (slightly differs from loop)

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=CYP_3A_intestine_final_wPred, pch=16)
abline(a=0, b=1)


### Unconditional ####
# Pull out response and predictors
CYP_3A_intestine_preds <- CYP_3A_intestine[, c(2:48)] # original predictors
CYP_3A_intestine_preds[,1] <- round(CYP_3A_intestine_preds[,1], 2)
CYP_3A_intestine_preds_loop <- CYP_3A_intestine_preds 

p <- ncol(CYP_3A_intestine_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(CYP_3A_intestine_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=CYP_3A_intestine_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((CYP_3A_intestine_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(CYP_3A_intestine_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((CYP_3A_intestine_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(CYP_3A_intestine_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=1.0) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  CYP_3A_intestine_preds_loop <- CYP_3A_intestine_preds_loop[,!colnames(CYP_3A_intestine_preds_loop)==var.list[i]] # remove variable
  
}
beep(8)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)

# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse)) #20
which(OOB.mae==min(OOB.mae)) #32

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round#
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #40
which(OOB.mae_1==min(OOB.mae_1)) #36

#rounding?#

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh100.CYP3Aint.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh100.CYP3Aint.csv", row.names = FALSE)

# Refit final model
CYP_3A_intestine_final <- CYP_3A_intestine %>% dplyr::select(Effect, Metformin, Phenanthrene, Anthraquinone, Lidocaine, "Benzo[a]pyrene", Fluoranthene, `Methyl-1H-benzotriazole`, Pyrene, Carbazole, Cotinine, Venlafaxine)

set.seed(3)
cf.final <- cforest(Effect~., data=CYP_3A_intestine_final, control=cforest_unbiased(mtry=3, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
CYP_3A_intestine_final_wPred <- cbind(CYP_3A_intestine_final, cf.final.pred.oob)

# OOB error
mean(abs(CYP_3A_intestine_final$Effect-cf.final.pred.oob$Predicted_OOB))#0.630324
sqrt(mean((CYP_3A_intestine_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2))#0.9070116

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=CYP_3A_intestine_final_wPred, pch=16)
abline(a=0, b=1)

#################CYP 2AD6 intestine 2017 ########### 
# Pull out relevant columns
names(cyp_2ad6_2017)
cyp_2ad6_2017_sub <- cyp_2ad6_2017[,c(2:41)]
cyp_2ad6_2017_sub[,1] <- round(cyp_2ad6_2017_sub[,1], 2)
p <-ncol(cyp_2ad6_2017)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=cyp_2ad6_2017_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((cyp_2ad6_2017_sub$Effect-cf.pred)^2))#2.553201
mean(abs(cyp_2ad6_2017_sub$Effect-cf.pred)) #1.791588

# Plot predicted vs. observed
plot(y=cf.pred, x=cyp_2ad6_2017_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 

#changed threshold to help it permute
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.9, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional

# cf.cpi$perTree # VI values per tree
plot(cf.cpi, type="bar")


### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
cyp_2ad6_2017_preds <- cyp_2ad6_2017[, c(2:41)] # original predictors
cyp_2ad6_2017_preds[,1] <- round(cyp_2ad6_2017_preds[,1], 2)
cyp_2ad6_2017_preds_loop <- cyp_2ad6_2017_preds 

p <- ncol(cyp_2ad6_2017_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(cyp_2ad6_2017_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=cyp_2ad6_2017_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((cyp_2ad6_2017_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(cyp_2ad6_2017_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((cyp_2ad6_2017_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(cyp_2ad6_2017_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  cyp_2ad6_2017_preds_loop <- cyp_2ad6_2017_preds_loop[,!colnames(cyp_2ad6_2017_preds_loop)==var.list[i]] # remove variable
  
}
beep()

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse)) #33
which(OOB.mae==min(OOB.mae)) #26

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round & check estimates
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #34
which(OOB.mae_1==min(OOB.mae_1)) #29

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list,"cf_VI_at_iter_thresh90.CYP2AD6int.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.CYP2AD6int.csv", row.names = FALSE)
View(RFE_info)

# Refit final model
cyp_2ad6_2017_final <- cyp_2ad6_2017 %>% dplyr::select(Effect, Carbamazepine, 
                                                       Desvenlafaxine, 
                                                       Lidocaine, Tramadol, 
                                                       Cholesterol, Venlafaxine,
                                                       "N,N-diethyl-meta-toluamide", Metformin,
                                                       Fexofenadine, "3,4-Dichlorophenyl isocyanate", Metolachlor)

set.seed(3)
cf.final <- cforest(Effect~., data=cyp_2ad6_2017_final, control=cforest_unbiased(mtry=4, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
cyp_2ad6_2017_final_wPred <- cbind(cyp_2ad6_2017_final, cf.final.pred.oob)

# OOB error
mean(abs(cyp_2ad6_2017_final$Effect-cf.final.pred.oob$Predicted_OOB))#1.678386
sqrt(mean((cyp_2ad6_2017_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2))#2.478894 

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=cyp_2ad6_2017_final_wPred, pch=16)
abline(a=0, b=1)


### Unconditional ####

# Pull out response and predictors - columns 5, 7-53
cyp_2ad6_2017_preds <- cyp_2ad6_2017[, c(2:48)] # original predictors
cyp_2ad6_2017_preds[,1] <- round(cyp_2ad6_2017_preds[,1], 2)
cyp_2ad6_2017_preds_loop <- cyp_2ad6_2017_preds 

p <- ncol(cyp_2ad6_2017_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(cyp_2ad6_2017_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=cyp_2ad6_2017_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((cyp_2ad6_2017_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(cyp_2ad6_2017_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((cyp_2ad6_2017_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(cyp_2ad6_2017_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=1.0) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  cyp_2ad6_2017_preds_loop <- cyp_2ad6_2017_preds_loop[,!colnames(cyp_2ad6_2017_preds_loop)==var.list[i]] # remove variable
  
}

beep()
# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse)) #35
which(OOB.mae==min(OOB.mae)) #26 

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round 
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #38
which(OOB.mae_1==min(OOB.mae_1)) #38 

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list,"cf_VI_at_iter_thresh100.CYP2AD6int.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_VI_at_iter_thresh100.CYP2AD6int.csv", row.names = FALSE)

# Refit final model
cyp_2ad6_2017_final <- cyp_2ad6_2017 %>% dplyr::select(Effect, `Triphenyl phosphate`, Metformin, Venlafaxine, Lidocaine, Tramadol, Carbamazepine, Desvenlafaxine, Cholesterol, Fexofenadine)

set.seed(3)
cf.final <- cforest(Effect~., data=cyp_2ad6_2017_final, control=cforest_unbiased(mtry=3, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
cyp_2ad6_2017_final_wPred <- cbind(cyp_2ad6_2017_final, cf.final.pred.oob)

# OOB error
mean(abs(cyp_2ad6_2017_final$Effect-cf.final.pred.oob$Predicted_OOB))#1.678041
sqrt(mean((cyp_2ad6_2017_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2))#2.476691

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=cyp_2ad6_2017_final_wPred, pch=16)
abline(a=0, b=1)


#################CYP 2N13 intestine 2017 ########### 
# Pull out relevant columns
names(cyp_2n13_2017)
cyp_2n13_2017_sub <- cyp_2n13_2017[,c(2:41)]
cyp_2n13_2017_sub[,1] <- round(cyp_2n13_2017_sub[,1], 2)
p <-ncol(cyp_2n13_2017)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=cyp_2n13_2017_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((cyp_2n13_2017_sub$Effect-cf.pred)^2)) #10.22242
mean(abs(cyp_2n13_2017_sub$Effect-cf.pred)) #5.449126

# Plot predicted vs. observed
plot(y=cf.pred, x=cyp_2n13_2017_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional

# cf.cpi$perTree # VI values per tree
plot(cf.cpi, type="bar")

### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
cyp_2n13_2017_preds <- cyp_2n13_2017[, c(2:41)] # original predictors
cyp_2n13_2017_preds[,1] <- round(cyp_2n13_2017_preds[,1], 2)
cyp_2n13_2017_preds_loop <- cyp_2n13_2017_preds 

p <- ncol(cyp_2n13_2017_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(cyp_2n13_2017_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=cyp_2n13_2017_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((cyp_2n13_2017_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(cyp_2n13_2017_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((cyp_2n13_2017_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(cyp_2n13_2017_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  cyp_2n13_2017_preds_loop <- cyp_2n13_2017_preds_loop[,!colnames(cyp_2n13_2017_preds_loop)==var.list[i]] # remove variable
  
}
beep(8)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse)) #40
which(OOB.mae==min(OOB.mae)) #30
var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #33
which(OOB.mae_1==min(OOB.mae_1)) #24


# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90_cyp2N13.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90_cyp2N13.csv", row.names = FALSE)

# Refit final model
cyp_2n13_2017_final <- cyp_2n13_2017 %>% dplyr::select(Effect,
                                                       Fexofenadine, "N,N-diethyl-meta-toluamide",
                                                       Indole, `Tris(2-butoxyethyl)phosphate`, Metformin, `Methyl-1H-benzotriazole`,
                                                       Nicotine,Carbamazepine, Tramadol, Desvenlafaxine,
                                                        Venlafaxine, Lidocaine)

set.seed(3)
cf.final <- cforest(Effect~., data=cyp_2n13_2017_final, control=cforest_unbiased(mtry=4, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
cyp_2n13_2017_final_wPred <- cbind(cyp_2n13_2017_final, cf.final.pred.oob)

# OOB error
mean(abs(cyp_2n13_2017_final$Effect-cf.final.pred.oob$Predicted_OOB)) #5.432168 
sqrt(mean((cyp_2n13_2017_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) #10.20128

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=cyp_2n13_2017_final_wPred, pch=16)
abline(a=0, b=1)

# Single variable partial dependence plots

cyp2n13_carbamazepine_pd <- partial(cf.final, pred.var="Carbamazepine", grid.resolution = 10)
cyp2n13_desvenla_pd <- partial(cf.final, pred.var="Venlafaxine", grid.resolution = 10)
cyp2n13_fexofen_pd <- partial(cf.final, pred.var="Fexofenadine", grid.resolution = 10)
cyp2n13_indole_pd <- partial(cf.final, pred.var="Indole", grid.resolution = 10)
cyp2n13_lidocaine_pd <- partial(cf.final, pred.var="Lidocaine", grid.resolution = 10)
cyp2n13_metformin_pd <- partial(cf.final, pred.var="Metformin", grid.resolution = 10)
cyp2n13_m1Hbt_pd <- partial(cf.final, pred.var="Methyl-1H-benzotriazole", grid.resolution = 10)
cyp2n13_nic_pd <- partial(cf.final, pred.var="Nicotine", grid.resolution = 10)
cyp2n13_tramadol_pd <- partial(cf.final, pred.var="Tramadol", grid.resolution = 10)
cyp2n13_t2bep_pd <- partial(cf.final, pred.var="Tris(2-butoxyethyl)phosphate", grid.resolution = 10)
cyp2n13_venla_pd <- partial(cf.final, pred.var="Desvenlafaxine", grid.resolution = 10)


cyp2n13_carbamazepine_pdp <- autoplot(cyp2n13_carbamazepine_pd, size=1.2) + theme_classic() + xlab("Carbamazepine") + ylab("Effect") +
  theme(text=element_text(size=20))
cyp2n13_desvenla_pdp <- autoplot(cyp2n13_desvenla_pd, size=1.2) + theme_classic() + xlab("Desvenlafaxine") + ylab("Effect") +
  theme(text=element_text(size=20))
cyp2n13_fexofen_pdp <- autoplot(cyp2n13_fexofen_pd, size=1.2) + theme_classic() + xlab("Fexofenadine") + ylab("Effect") +
  theme(text=element_text(size=20))
cyp2n13_indole_pdp <- autoplot(cyp2n13_indole_pd, size=1.2) + theme_classic() + xlab("Indole") + ylab("Effect") +
  theme(text=element_text(size=20))
cyp2n13_lidocaine_pdp <- autoplot(cyp2n13_lidocaine_pd, size=1.2) + theme_classic() + xlab("Lidocaine") + ylab("Effect") +
  theme(text=element_text(size=20))
cyp2n13_metformin_pdp <- autoplot(cyp2n13_metformin_pd, size=1.2) + theme_classic() + xlab("Metformin") + ylab("Effect") +
  theme(text=element_text(size=20))
cyp2n13_m1Hbt_pdp <- autoplot(cyp2n13_m1Hbt_pd, size=1.2) + theme_classic() + xlab("Methyl-1H-benzotriazole") + ylab("Effect") +
  theme(text=element_text(size=20))
cyp2n13_nic_pdp <- autoplot(cyp2n13_nic_pd, size=1.2) + theme_classic() + xlab("Nicotine") + ylab("Effect") +
  theme(text=element_text(size=20))
cyp2n13_tramadol_pdp <- autoplot(cyp2n13_tramadol_pd, size=1.2) + theme_classic() + xlab("Tramadol") + ylab("Effect") +
  theme(text=element_text(size=20))
cyp2n13_t2bep_pdp <- autoplot(cyp2n13_t2bep_pd, size=1.2) + theme_classic() + xlab("Tris(2-butoxyethyl)phosphate") + ylab("Effect") +
  theme(text=element_text(size=20))
cyp2n13_venla_pdp <- autoplot(cyp2n13_venla_pd, size=1.2) + theme_classic() + xlab("Venlafaxine") + ylab("Effect") +
  theme(text=element_text(size=20))

cyp2n13 <- grid.arrange(cyp2n13_carbamazepine_pdp, cyp2n13_desvenla_pdp, cyp2n13_fexofen_pdp,
                        cyp2n13_indole_pdp,cyp2n13_lidocaine_pdp, cyp2n13_metformin_pdp,
                        cyp2n13_m1Hbt_pdp,cyp2n13_nic_pdp, cyp2n13_tramadol_pdp,
                        cyp2n13_t2bep_pdp, cyp2n13_venla_pdp, ncol = 3)
ggsave("CYP2N13.jpeg", cyp2n13, height = 20, width = 20)

###unconditional####
# Pull out response and predictors - columns 5, 7-53
cyp_2n13_2017_preds <- cyp_2n13_2017[, c(2:48)] # original predictors
cyp_2n13_2017_preds[,1] <- round(cyp_2n13_2017_preds[,1], 2)

cyp_2n13_2017_preds_loop <- cyp_2n13_2017_preds 

p <- ncol(cyp_2n13_2017_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(cyp_2n13_2017_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=cyp_2n13_2017_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((cyp_2n13_2017_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(cyp_2n13_2017_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((cyp_2n13_2017_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(cyp_2n13_2017_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=1) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  cyp_2n13_2017_preds_loop <- cyp_2n13_2017_preds_loop[,!colnames(cyp_2n13_2017_preds_loop)==var.list[i]] # remove variable
  
}
beep(5)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#46
which(OOB.mae==min(OOB.mae))#29
var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1))#46
which(OOB.mae_1==min(OOB.mae_1))#29
var.list[which(OOB.mae_1==min(OOB.mae_1)):length(OOB.mae_1)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh1000_cyp2N13.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh100_cyp2N13.csv", row.names = FALSE)

# Refit final model
cyp_2n13_2017_final <- cyp_2n13_2017 %>% dplyr::select(Effect, Atrazine, Caffeine, Diltiazem, Guanylurea, Nicotine, Indole, `Triphenyl phosphate`, `3,4-Dichlorophenyl isocyanate`, `Methyl-1H-benzotriazole`, Hexamethylenetetramine, Metformin, `Tris(2-butoxyethyl)phosphate`, Fexofenadine, Tramadol, Carbamazepine, Lidocaine, Desvenlafaxine, Venlafaxine)

set.seed(3)
cf.final <- cforest(Effect~., data=cyp_2n13_2017_final, control=cforest_unbiased(mtry=6, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
cyp_2n13_2017_final_wPred <- cbind(cyp_2n13_2017_final, cf.final.pred.oob)

# OOB error
mean(abs(cyp_2n13_2017_final$Effect-cf.final.pred.oob$Predicted_OOB))#5.435469 
sqrt(mean((cyp_2n13_2017_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2))#10.21133

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=cyp_2n13_2017_final_wPred, pch=16)
abline(a=0, b=1)

#################UGT1A1 Liver 2017 ########### 
# Pull out relevant columns
names(ugt_1a1_liver)
ugt_1a1_liver_sub <- ugt_1a1_liver[,c(2:41)]
ugt_1a1_liver_sub[,1] <- round(ugt_1a1_liver_sub[,1], 2)

p <-ncol(ugt_1a1_liver)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=ugt_1a1_liver_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((ugt_1a1_liver_sub$Effect-cf.pred)^2)) #1.837906
mean(abs(ugt_1a1_liver_sub$Effect-cf.pred)) #1.252773

# Plot predicted vs. observed
plot(y=cf.pred, x=ugt_1a1_liver_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
#changed threshold to help it permute
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.9, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional

# cf.cpi$perTree # VI values per tree
plot(cf.cpi, type="bar")

### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
ugt_1a1_liver_preds <- ugt_1a1_liver[, c(2:41)] # original predictors
ugt_1a1_liver_preds[,1] <- round(ugt_1a1_liver_preds[,1], 2)
ugt_1a1_liver_preds_loop <- ugt_1a1_liver_preds 

p <- ncol(ugt_1a1_liver_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(ugt_1a1_liver_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=ugt_1a1_liver_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((ugt_1a1_liver_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(ugt_1a1_liver_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((ugt_1a1_liver_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(ugt_1a1_liver_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  ugt_1a1_liver_preds_loop <- ugt_1a1_liver_preds_loop[,!colnames(ugt_1a1_liver_preds_loop)==var.list[i]] # remove variable
  
}
beep(4)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse)) #41
which(OOB.mae==min(OOB.mae)) #41
var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)] #fexofenadine

#round
OOB.mae_1 <- round(OOB.mae, 2)
OOB.rmse_1 <- round(OOB.rmse, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #41
which(OOB.mae_1==min(OOB.mae_1)) #41
var.list[which(OOB.mae_1==min(OOB.mae_1)):length(OOB.mae_1)] #fexofenadine

#same#

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90_ugt1a1_liver.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90_ugt1a1_liver.csv", row.names = FALSE)

# Refit final model
ugt_1a1_liver_final <- ugt_1a1_liver %>% dplyr::select(Effect, Fexofenadine, Isophorone)

set.seed(3)
cf.final <- cforest(Effect~., data=ugt_1a1_liver_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
ugt_1a1_liver_final_wPred <- cbind(ugt_1a1_liver_final, cf.final.pred.oob)

# OOB error
mean(abs(ugt_1a1_liver_final$Effect-cf.final.pred.oob$Predicted_OOB)) ##1.06774
sqrt(mean((ugt_1a1_liver_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) # 1.675572 (slightly differs from loop)

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=ugt_1a1_liver_final_wPred, pch=16)
abline(a=0, b=1)

# Single variable partial dependence plots
cf.partial1 <- partial(cf.final, pred.var="Fexofenadine", grid.resolution = 10)
cf.partial2 <- partial(cf.final, pred.var="Isophorone", grid.resolution = 10)

ugt1a1_liv_fexo <- autoplot(cf.partial1, size=1.2) + theme_classic() + xlab("Fexofenadine") + ylab("Effect") +
  theme(text=element_text(size=20))
ugt1a1_liv_iso <- autoplot(cf.partial2, size=1.2) + theme_classic() + xlab("Isophorone") + ylab("Effect") +
  theme(text=element_text(size=20))

ugt1a1_liver_pdp <- grid.arrange(ugt1a1_liv_fexo, ugt1a1_liv_iso)
ggsave("UGT1A1_liver.jpeg", ugt1a1_liver_pdp)

### Unconditional ####

# Pull out response and predictors - columns 5, 7-53
ugt_1a1_liver_preds <- ugt_1a1_liver[, c(2:48)] # original predictors
ugt_1a1_liver_preds[,1] <- round(ugt_1a1_liver_preds[,1], 2)
ugt_1a1_liver_preds_loop <- ugt_1a1_liver_preds 

p <- ncol(ugt_1a1_liver_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(ugt_1a1_liver_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=ugt_1a1_liver_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((ugt_1a1_liver_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(ugt_1a1_liver_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((ugt_1a1_liver_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(ugt_1a1_liver_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=1) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  ugt_1a1_liver_preds_loop <- ugt_1a1_liver_preds_loop[,!colnames(ugt_1a1_liver_preds_loop)==var.list[i]] # remove variable
  
}
beep(4)
# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#46
which(OOB.mae==min(OOB.mae))#46

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)] #fexofenadine

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh100_ugt1a1_liver.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh100_ugt1a1_liver.csv", row.names = FALSE)

# Refit final model
ugt_1a1_liver_final <- ugt_1a1_liver %>% dplyr::select(Effect, Fexofenadine)

set.seed(3)
cf.final <- cforest(Effect~., data=ugt_1a1_liver_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
ugt_1a1_liver_final_wPred <- cbind(ugt_1a1_liver_final, cf.final.pred.oob)

# OOB error
mean(abs(ugt_1a1_liver_final$Effect-cf.final.pred.oob$Predicted_OOB)) ##1.06774
sqrt(mean((ugt_1a1_liver_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) # 1.675187 (slightly differs from loop)

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=ugt_1a1_liver_final_wPred, pch=16)
abline(a=0, b=1)


#################UGT1A1 Intestine 2017 ########### 
# Pull out relevant columns
names(ugt_1a1_intestine)
ugt_1a1_intestine_sub <- ugt_1a1_intestine[,c(2:41)]
ugt_1a1_intestine_sub[,1] <- round(ugt_1a1_intestine_sub[,1], 2)
p <-ncol(ugt_1a1_intestine)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=ugt_1a1_intestine_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((ugt_1a1_intestine_sub$Effect-cf.pred)^2)) #3.718351
mean(abs(ugt_1a1_intestine_sub$Effect-cf.pred)) #3.484806

# Plot predicted vs. observed
plot(y=cf.pred, x=ugt_1a1_intestine_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9, can try values between 0.8-1)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.9, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional

# cf.cpi$perTree # VI values per tree
plot(cf.cpi, type="bar")


### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
ugt_1a1_intestine_preds <- ugt_1a1_intestine[, c(2:41)] # original predictors
ugt_1a1_intestine_preds[,1] <- round(ugt_1a1_intestine_preds[,1], 2)
ugt_1a1_intestine_preds_loop <- ugt_1a1_intestine_preds 

p <- ncol(ugt_1a1_intestine_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(ugt_1a1_intestine_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=ugt_1a1_intestine_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((ugt_1a1_intestine_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(ugt_1a1_intestine_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((ugt_1a1_intestine_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(ugt_1a1_intestine_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  ugt_1a1_intestine_preds_loop <- ugt_1a1_intestine_preds_loop[,!colnames(ugt_1a1_intestine_preds_loop)==var.list[i]] # remove variable
  
}
beep(4)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse)) #16
which(OOB.mae==min(OOB.mae)) #16

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #32
which(OOB.mae_1==min(OOB.mae_1)) #20

var.list[which(OOB.mae_1==min(OOB.mae_1)):length(OOB.mae_1)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90_ugt1a1_intestine.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90_ugt1a1_intestine.csv", row.names = FALSE)

View(RFE_info)

# Refit final model
ugt_1a1_intestine_final <- ugt_1a1_intestine %>% dplyr::select(Effect, Carbamazepine,Cholesterol, Desvenlafaxine, 
                                                               Fexofenadine,Fluoranthene,Isophorone,
                                                               Lidocaine,Metformin, Methotrexate, "N,N-diethyl-meta-toluamide",
                                                               Triamterene,Sulfamethoxazole, 
                                                               Tramadol, 
                                                               Venlafaxine,
                                                               "Tris(2-butoxyethyl)phosphate", Indole, "Benzo[a]pyrene",
                                                               "Bisphenol A", "3,4-Dichlorophenyl isocyanate", Phenanthrene)
                                                               
set.seed(3)
cf.final <- cforest(Effect~., data=ugt_1a1_intestine_final, control=cforest_unbiased(mtry=5, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
ugt_1a1_intestine_final_wPred <- cbind(ugt_1a1_intestine_final, cf.final.pred.oob)

# OOB error
mean(abs(ugt_1a1_intestine_final$Effect-cf.final.pred.oob$Predicted_OOB))#3.451744
sqrt(mean((ugt_1a1_intestine_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2))#5.83524

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=ugt_1a1_intestine_final_wPred, pch=16)
abline(a=0, b=1)

# Single variable partial dependence plots
ugt1a1_int_carba_pd <- partial(cf.final, pred.var="Carbamazepine", grid.resolution = 10)
ugt1a1_int_cholesterol_pd <- partial(cf.final, pred.var="Cholesterol", grid.resolution = 10)
ugt1a1_int_desvenla_pd <- partial(cf.final, pred.var="Desvenlafaxine", grid.resolution = 10)
ugt1a1_int_fexo_pd <- partial(cf.final, pred.var="Fexofenadine", grid.resolution = 10)
ugt1a1_int_fluor_pd <- partial(cf.final, pred.var="Fluoranthene", grid.resolution = 10)
ugt1a1_int_isophorone_pd <- partial(cf.final, pred.var="Isophorone", grid.resolution = 10)
ugt1a1_int_lido_pd <- partial(cf.final, pred.var="Lidocaine", grid.resolution = 10)
ugt1a1_int_metfor_pd <- partial(cf.final, pred.var="Metformin", grid.resolution = 10)
ugt1a1_int_methotrex_pd <- partial(cf.final, pred.var="Methotrexate", grid.resolution = 10)
ugt1a1_int_deet_pd <- partial(cf.final, pred.var="N,N-diethyl-meta-toluamide", grid.resolution = 10)
ugt1a1_int_triam_pd <- partial(cf.final, pred.var="Triamterene", grid.resolution = 10)
ugt1a1_int_sulfa_pd <- partial(cf.final, pred.var="Sulfamethoxazole", grid.resolution = 10)
ugt1a1_int_tramadol_pd <- partial(cf.final, pred.var="Tramadol", grid.resolution = 10)
ugt1a1_int_venla_pd <- partial(cf.final, pred.var="Venlafaxine", grid.resolution = 10)

ugt1a1_int_carba_pdp <- autoplot(ugt1a1_int_carba_pd, size=1.2) + theme_classic() + xlab("Carbamazepine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_cholesterol_pdp <- autoplot(ugt1a1_int_cholesterol_pd, size=1.2) + theme_classic() + xlab("Cholesterol") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_desvenla_pdp <- autoplot(ugt1a1_int_desvenla_pd, size=1.2) + theme_classic() + xlab("Desvenlafaxine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_fexo_pdp <- autoplot(ugt1a1_int_fexo_pd, size=1.2) + theme_classic() + xlab("Fexofenadine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_fluor_pdp <- autoplot(ugt1a1_int_fluor_pd, size=1.2) + theme_classic() + xlab("Fluoranthene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_isophorone_pdp <- autoplot(ugt1a1_int_isophorone_pd, size=1.2) + theme_classic() + xlab("Isophorone") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_lido_pdp <- autoplot(ugt1a1_int_lido_pd, size=1.2) + theme_classic() + xlab("Lidocaine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_metfor_pdp <- autoplot(ugt1a1_int_metfor_pd, size=1.2) + theme_classic() + xlab("Metformin") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_methotrex_pdp <- autoplot(ugt1a1_int_methotrex_pd, size=1.2) + theme_classic() + xlab("Methotrexate") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_deet_pdp <- autoplot(ugt1a1_int_deet_pd, size=1.2) + theme_classic() + xlab("N,N-diethyl-meta-toluamide") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_triam_pdp <- autoplot(ugt1a1_int_triam_pd, size=1.2) + theme_classic() + xlab("Triamterene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_sulfa_pdp <- autoplot(ugt1a1_int_sulfa_pd, size=1.2) + theme_classic() + xlab("Sulfamethoxazole") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_tramadol_pdp <- autoplot(ugt1a1_int_tramadol_pd, size=1.2) + theme_classic() + xlab("Tramadol") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_venla_pdp <- autoplot(ugt1a1_int_venla_pd, size=1.2) + theme_classic() + xlab("Venlafaxine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")

ugt1a1 <- grid.arrange(ugt1a1_int_carba_pdp, ugt1a1_int_cholesterol_pdp, ugt1a1_int_desvenla_pdp,
                       ugt1a1_int_fexo_pdp, ugt1a1_int_fluor_pdp, ugt1a1_int_isophorone_pdp,
                       ugt1a1_int_lido_pdp, ugt1a1_int_metfor_pdp, ugt1a1_int_methotrex_pdp,
                       ugt1a1_int_deet_pdp, ugt1a1_int_triam_pdp, ugt1a1_int_sulfa_pdp,
                       ugt1a1_int_tramadol_pdp, ugt1a1_int_venla_pdp,
             ncol = 3)

ggsave("UGT1A1.jpeg", ugt1a1, height = 20, width = 20)

### Unconditional ####

# Pull out response and predictors - columns 5, 7-53
ugt_1a1_intestine_preds <- ugt_1a1_intestine[, c(2:48)] # original predictors
ugt_1a1_intestine_preds[,1] <- round(ugt_1a1_intestine_preds[,1], 2)
ugt_1a1_intestine_preds_loop <- ugt_1a1_intestine_preds 

p <- ncol(ugt_1a1_intestine_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(ugt_1a1_intestine_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=ugt_1a1_intestine_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((ugt_1a1_intestine_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(ugt_1a1_intestine_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((ugt_1a1_intestine_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(ugt_1a1_intestine_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=1.0) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  ugt_1a1_intestine_preds_loop <- ugt_1a1_intestine_preds_loop[,!colnames(ugt_1a1_intestine_preds_loop)==var.list[i]] # remove variable
  
}
beep()

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse)) #44
which(OOB.mae==min(OOB.mae)) #23

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #44
which(OOB.mae_1==min(OOB.mae_1)) #29

var.list[which(OOB.mae_1==min(OOB.mae_1)):length(OOB.mae_1)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh100_ugt1a1_intestine.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh100_ugt1a1_intestine.csv", row.names = FALSE)

# Refit final model
ugt_1a1_intestine_final <- ugt_1a1_intestine %>% dplyr::select(Effect, `Triphenyl phosphate`, Triamterene, `Tris(2-butoxyethyl)phosphate`, Indole, Cholesterol, Methotrexate, Isophorone, Sulfamethoxazole, Tramadol, Codeine, Diltiazem, Fluoranthene, Carbamazepine, Metformin, Desvenlafaxine, Fexofenadine, Lidocaine, Venlafaxine)

set.seed(3)
cf.final <- cforest(Effect~., data=ugt_1a1_intestine_final, control=cforest_unbiased(mtry=4, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
ugt_1a1_intestine_final_wPred <- cbind(ugt_1a1_intestine_final, cf.final.pred.oob)

# OOB error
mean(abs(ugt_1a1_intestine_final$Effect-cf.final.pred.oob$Predicted_OOB)) ##3.442833
sqrt(mean((ugt_1a1_intestine_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) # 5.831045 (slightly differs from loop)

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=ugt_1a1_intestine_final_wPred, pch=16)
abline(a=0, b=1)


#################T47########### 
# Pull out relevant columns
names(t47.allyears)
View(t47.allyears)
t47_sub <- t47.allyears[,c(2, 4:80)]
names(t47_sub)

t47_sub[,1] <- round(t47_sub[,1], 2)
p <-ncol(t47)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=t47_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((t47_sub$Effect-cf.pred)^2)) #0.1813468
mean(abs(t47_sub$Effect-cf.pred)) #0.1357415

# Plot predicted vs. observed
plot(y=cf.pred, x=t47_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
#changed threshold to help it permute
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.9, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional

# cf.cpi$perTree # VI values per tree
plot(cf.cpi, type="bar")

### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
names(t47.allyears)
t47_preds <- t47.allyears[,c(2, 4:80)]
t47_preds[,1] <- round(t47_preds[,1], 2)
t47_preds_loop <- t47_preds 

p <- ncol(t47_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(t47_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=t47_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((t47_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(t47_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((t47_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(t47_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  t47_preds_loop <- t47_preds_loop[,!colnames(t47_preds_loop)==var.list[i]] # remove variable
  
}
beep(9)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse)) #56
which(OOB.mae==min(OOB.mae)) #56

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# [1] "Methyl-1H-benzotriazole" "Cholesterol"             "Dextromethorphan"        "beta-Sitosterol"   

OOB.mae_1 <- round(OOB.mae, 2)
OOB.rmse_1 <- round(OOB.rmse, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #73
which(OOB.mae_1==min(OOB.mae_1)) #73

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#same

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90_t47.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90_t47.csv", row.names = FALSE)

# Refit final model
t47_final <- t47.allyears %>% dplyr::select(Effect,`beta-Sitosterol`, Cholesterol, Dextromethorphan,
                                            `Methyl-1H-benzotriazole`)

set.seed(3)
cf.final <- cforest(Effect~., data=t47_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
t47_final_wPred <- cbind(t47_final, cf.final.pred.oob)

# OOB error
mean(abs(t47_final$Effect-cf.final.pred.oob$Predicted_OOB))#0.1322002 
sqrt(mean((t47_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) # 0.1768888 

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=t47_final_wPred, pch=16)
abline(a=0, b=1)

# Single variable partial dependence plots
t47_bss_pd <- partial(cf.final, pred.var="beta-Sitosterol", grid.resolution = 10)
t47_chol_pd <- partial(cf.final, pred.var="Cholesterol", grid.resolution = 10)
t47_dex_pd <- partial(cf.final, pred.var="Dextromethorphan", grid.resolution = 10)
t47_m1hbt_pd <- partial(cf.final, pred.var="Methyl-1H-benzotriazole", grid.resolution = 10)

t47_bss_pdp <- autoplot(t47_bss_pd, size=1.2) + theme_classic() + xlab("beta-Sitosterol") + ylab("Effect") +
  theme(text=element_text(size=20))
t47_chol_pdp <- autoplot(t47_chol_pd, size=1.2) + theme_classic() + xlab("Cholesterol") + ylab("Effect") +
  theme(text=element_text(size=20))
t47_dex_pdp <- autoplot(t47_dex_pd, size=1.2) + theme_classic() + xlab("Dextromethorphan") + ylab("Effect") +
  theme(text=element_text(size=20))
t47_m1hbt_pdp <- autoplot(t47_m1hbt_pd, size=1.2) + theme_classic() + xlab("Methyl-1H-benzotriazole") + ylab("Effect") +
  theme(text=element_text(size=20))


t47 <- grid.arrange(t47_bss_pdp, t47_chol_pdp, t47_tram_pdp, t47_dex_pdp, t47_bup_pdp,t47_m1hbt_pdp, 
                    t47_metoprolol_pdp, t47_camp_pdp,t47_cot_pdp, t47_3b_pdp, t47_hhcb_pdp,
  ncol = 3)
ggsave("T47.jpeg", t47, height = 20, width = 20)

### Unconditional ####
# Pull out response and predictors - columns 5, 7-53
t47_preds <- t47.allyears[,c(2, 4:88)]
t47_preds[,1] <- round(t47_preds[,1], 1)
t47_preds_loop <- t47_preds 

p <- ncol(t47_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(t47_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=t47_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((t47_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(t47_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((t47_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(t47_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=1) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  t47_preds_loop <- t47_preds_loop[,!colnames(t47_preds_loop)==var.list[i]] # remove variable
  
}
beep()

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)

# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse)) #79
which(OOB.mae==min(OOB.mae)) #79

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round it

OOB.mae_1 <- round(OOB.mae, 2)
OOB.rmse_1 <- round(OOB.rmse, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #89
which(OOB.mae_1==min(OOB.mae_1)) #79

var.list[which(OOB.mae_1==min(OOB.mae_1)):length(OOB.mae_1)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh100_t47.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh100_t47.csv", row.names = FALSE)

# Refit final model
t47_final <- t47.allyears %>% dplyr::select(Effect, `Tris(2-butoxyethyl)phosphate`, `Methyl-1H-benzotriazole`, `Tris(dichloroisopropyl)phosphate`, `beta-Sitosterol`, Cholesterol, Dextromethorphan, Gabapentin)

set.seed(3)
cf.final <- cforest(Effect~., data=t47_final, control=cforest_unbiased(mtry=2, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
t47_final_wPred <- cbind(t47_final, cf.final.pred.oob)

# OOB error
mean(abs(t47_final$Effect-cf.final.pred.oob$Predicted_OOB)) ##0.1841943
sqrt(mean((t47_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) # 0.248793 (slightly differs from loop)

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=t47_final_wPred, pch=16)
abline(a=0, b=1)


################# AhR ########### 
# Pull out relevant columns
names(ahr)
ahr_sub <- ahr[,c(2, 4:80)]
ahr_sub[,1] <- round(ahr_sub[,1], 2)
View(ahr_sub)
p <-ncol(ahr_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=ahr_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((ahr_sub$Effect-cf.pred)^2)) # 1.208781
mean(abs(ahr_sub$Effect-cf.pred)) # 0.8535622

# Plot predicted vs. observed
plot(y=cf.pred, x=ahr_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9, can try values between 0.8-1)
set.seed(3) 
#increased threshold from 0.9 - 0.95 to help permute 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional

# cf.cpi$perTree # VI values per tree
plot(cf.cpi, type="bar")

### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
names(ahr)
ahr_preds <- ahr[, c(2, 4:80)] # original predictors
ahr_preds[,1] <- round(ahr_preds[,1],2)
ahr_preds_loop <- ahr_preds 

p <- ncol(ahr_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(ahr_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=ahr_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((ahr_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(ahr_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((ahr_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(ahr_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  ahr_preds_loop <- ahr_preds_loop[,!colnames(ahr_preds_loop)==var.list[i]] # remove variable
  
}
beep(7)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)

# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#69
which(OOB.mae==min(OOB.mae))#72

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round#
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1))#72
which(OOB.mae_1==min(OOB.mae_1))#72

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90.ahr.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.ahr.csv", row.names = FALSE)

# Refit final model
ahr_final <- ahr %>% dplyr::select(Effect, "Caffeine", "Cotinine", "Anthraquinone", "Acetaminophen", "Carbazole", "Pyrene", "Phenanthrene", "Fluoranthene", "Benzo[a]pyrene", "Methyl-1H-benzotriazole", "Atrazine", "Tris(dichloroisopropyl)phosphate", "Nicotine", "Triphenyl phosphate", "Triethyl citrate", "Triclosan", "Tribromomethane", "Thiabendazole"
)

set.seed(3)
cf.final <- cforest(Effect~., data=ahr_final, control=cforest_unbiased(mtry=6, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
ahr_final_wPred <- cbind(ahr_final, cf.final.pred.oob)

# OOB error
mean(abs(ahr$Effect-cf.final.pred.oob$Predicted_OOB)) #0.8581219
sqrt(mean((ahr_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) #1.208691

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=ahr_final_wPred, pch=16)
abline(a=0, b=1)


### Unconditional ####

# Pull out response and predictors - columns 5, 7-53
ahr_preds <- ahr[, c(2, 4:86)] # original predictors
ahr_preds[,1] <- round(ahr_preds[,1], 2)
ahr_preds_loop <- ahr_preds 

p <- ncol(ahr_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(ahr_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=ahr_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((ahr_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(ahr_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((ahr_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(ahr_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=1.0) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  ahr_preds_loop <- ahr_preds_loop[,!colnames(ahr_preds_loop)==var.list[i]] # remove variable
  
}
beep(5)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#75
which(OOB.mae==min(OOB.mae))#77
var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1))#75
which(OOB.mae_1==min(OOB.mae_1))#77
var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh100.ahr.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh100.ahr.csv", row.names = FALSE)


# Refit final model
ahr_final <- ahr %>% dplyr::select(Effect, Phenanthrene, Anthraquinone, `Tris(dichloroisopropyl)phosphate`)

set.seed(3)
cf.final <- cforest(Effect~., data=ahr_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
ahr_final_wPred <- cbind(ahr_final, cf.final.pred.oob)

# OOB error
mean(abs(ahr$Effect-cf.final.pred.oob$Predicted_OOB)) # 2.830665
sqrt(mean((ahr_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) # 3.611087 (slightly differs from loop)

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=ahr_final_wPred, pch=16)
abline(a=0, b=1)


#################PXR-CIS ########### 
# Pull out relevant columns
names(PXR_cis)
PXR_cis_sub <- PXR_cis[,c(2, 4:80)]
PXR_cis_sub[,1] <- round(PXR_cis_sub[,1], 2)
p <-ncol(PXR_cis_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=PXR_cis_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((PXR_cis_sub$Effect-cf.pred)^2)) #0.8773743
mean(abs(PXR_cis_sub$Effect-cf.pred)) #0.6716497

# Plot predicted vs. observed
plot(y=cf.pred, x=PXR_cis_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional

# cf.cpi$perTree # VI values per tree
plot(cf.cpi, type="bar")


### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
PXR_cis_preds <- PXR_cis[, c(2, 4:80)] # original predictors
PXR_cis_preds[,1] <- round(PXR_cis_preds[,1])
PXR_cis_preds_loop <- PXR_cis_preds 

p <- ncol(PXR_cis_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(PXR_cis_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=PXR_cis_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((PXR_cis_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(PXR_cis_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((PXR_cis_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(PXR_cis_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  PXR_cis_preds_loop <- PXR_cis_preds_loop[,!colnames(PXR_cis_preds_loop)==var.list[i]] # remove variable
  
}
beep(4)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#66
which(OOB.mae==min(OOB.mae))#74

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.mae_1 <- round(OOB.mae,2)
OOB.rmse_1 <- round(OOB.rmse,2)

which(OOB.mae_1==min(OOB.mae_1))#74
which(OOB.rmse_1==min(OOB.rmse_1))#70

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90.PXR_cis.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.PXR_cis.csv", row.names = FALSE)
View(RFE_info)

# Refit final model
PXR_cis_final <- PXR_cis %>% dplyr::select(Effect, "beta-Sitosterol", "Atrazine", "3-beta-Coprostanol", "N,N-diethyl-meta-toluamide")

set.seed(3)
cf.final <- cforest(Effect~., data=PXR_cis_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
PXR_cis_final_wPred <- cbind(PXR_cis_final, cf.final.pred.oob)

# OOB error
mean(abs(PXR_cis_final$Effect-cf.final.pred.oob$Predicted_OOB)) ##0.5659017
sqrt(mean((PXR_cis_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) # 0.8123096 (slightly differs from loop)

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=PXR_cis_final_wPred, pch=16)
abline(a=0, b=1)

### Unconditional ####

PXR_cis_preds <- PXR_cis[, c(2, 4:86)] # original predictors
PXR_cis_preds[,1] <- round(PXR_cis_preds[,1], 2)
PXR_cis_preds_loop <- PXR_cis_preds 

p <- ncol(PXR_cis_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(PXR_cis_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=PXR_cis_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((PXR_cis_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(PXR_cis_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((PXR_cis_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(PXR_cis_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=1.0) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  PXR_cis_preds_loop <- PXR_cis_preds_loop[,!colnames(PXR_cis_preds_loop)==var.list[i]] # remove variable
  
}
beep(4)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))
which(OOB.mae==min(OOB.mae))

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.mae_1 <- round(OOB.mae, 2)
OOB.rmse_1 <- round(OOB.rmse, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #79
which(OOB.mae_1==min(OOB.mae_1)) #76

var.list[which(OOB.mae_1==min(OOB.mae_1)):length(OOB.mae_1)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh100.PXR_cis.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh100.PXR_cis.csv", row.names = FALSE)


# Refit final model
PXR_cis_final <- PXR_cis %>% dplyr::select(Effect, `Benzo[a]pyrene`, Anthraquinone, Carbazole, Phenanthrene, Caffeine, Pyrene, Hexamethylenetetramine)

set.seed(3)
cf.final <- cforest(Effect~., data=PXR_cis_final, control=cforest_unbiased(mtry=3, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
PXR_cis_final_wPred <- cbind(PXR_cis_final, cf.final.pred.oob)

# OOB error
mean(abs(PXR_cis_final$Effect-cf.final.pred.oob$Predicted_OOB)) #0.5752501
sqrt(mean((PXR_cis_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2))#0.8376488

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=PXR_cis_final_wPred, pch=16)
abline(a=0, b=1)


#################PXR-TRANS ########### 
# Pull out relevant columns
names(PXR_trans)
PXR_trans_sub <- PXR_trans[,c(2, 4:80)]
PXR_trans_sub[,1] <- round(PXR_trans_sub[,1], 2)
p <-ncol(PXR_trans_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=PXR_trans_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((PXR_trans_sub$Effect-cf.pred)^2))#0.5511089
mean(abs(PXR_trans_sub$Effect-cf.pred)) #0.4356607

# Plot predicted vs. observed
plot(y=cf.pred, x=PXR_trans_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional

# cf.cpi$perTree # VI values per tree
plot(cf.cpi, type="bar")


### Loop to recursively eliminate least informative variables ####

PXR_trans_preds <- PXR_trans[, c(2, 4:80)] # original predictors
PXR_trans_preds[,1] <- round(PXR_trans_preds[,1], 2)
PXR_trans_preds_loop <- PXR_trans_preds 

p <- ncol(PXR_trans_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(PXR_trans_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=PXR_trans_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((PXR_trans_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(PXR_trans_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((PXR_trans_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(PXR_trans_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  PXR_trans_preds_loop <- PXR_trans_preds_loop[,!colnames(PXR_trans_preds_loop)==var.list[i]] # remove variable
  
}
beep(7)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#68
which(OOB.mae==min(OOB.mae))#76

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1))#76
which(OOB.mae_1==min(OOB.mae_1))#76

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90.PXR_trans.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.PXR_trans.csv", row.names = FALSE)

# Refit final model
PXR_trans_final <- PXR_trans %>% dplyr::select(Effect, "N,N-diethyl-meta-toluamide", "beta-Sitosterol")

set.seed(3)
cf.final <- cforest(Effect~., data=PXR_trans_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
PXR_trans_final_wPred <- cbind(PXR_trans_final, cf.final.pred.oob)

# OOB error
mean(abs(PXR_trans_final$Effect-cf.final.pred.oob$Predicted_OOB)) ##0.4283596
sqrt(mean((PXR_trans_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) # 0.5125269 (slightly differs from loop)

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=PXR_trans_final_wPred, pch=16)
abline(a=0, b=1)

### Unconditional ####
PXR_trans_preds <- PXR_trans[, c(2, 4:86)] # original predictors
PXR_trans_preds[,1] <- round(PXR_trans_preds[,1], 2)
PXR_trans_preds_loop <- PXR_trans_preds 

p <- ncol(PXR_trans_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(PXR_trans_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=PXR_trans_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((PXR_trans_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(PXR_trans_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((PXR_trans_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(PXR_trans_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=1.0) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  PXR_trans_preds_loop <- PXR_trans_preds_loop[,!colnames(PXR_trans_preds_loop)==var.list[i]] # remove variable
  
}
beep(8)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse)) #81
which(OOB.mae==min(OOB.mae)) #81

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #81
which(OOB.mae_1==min(OOB.mae_1)) #81

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh100.PXR_trans.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh100.PXR_trans.csv", row.names = FALSE)


# Refit final model
PXR_trans_final <- PXR_trans %>% dplyr::select(Effect, Caffeine, `beta-Sitosterol`, `Methyl-1H-benzotriazole`)

set.seed(3)
cf.final <- cforest(Effect~., data=PXR_trans_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
PXR_trans_final_wPred <- cbind(PXR_trans_final, cf.final.pred.oob)

# OOB error
mean(abs(PXR_trans_final$Effect-cf.final.pred.oob$Predicted_OOB)) 
sqrt(mean((PXR_trans_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2))

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=PXR_trans_final_wPred, pch=16)
abline(a=0, b=1)


#################ERa ########### 
# Pull out relevant columns
names(ERa)
ERa_sub <- ERa[,c(2, 4:80)]
ERa_sub[,1] <- round(ERa_sub[,1])
p <-ncol(ERa_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=ERa_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((ERa_sub$Effect-cf.pred)^2))#0.5026376
mean(abs(ERa_sub$Effect-cf.pred)) #0.4115983

# Plot predicted vs. observed
plot(y=cf.pred, x=ERa_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional

# cf.cpi$perTree # VI values per tree
plot(cf.cpi, type="bar")

### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
ERa_preds <- ERa[, c(2, 4:80)] # original predictors
ERa_preds[,1] <- round(ERa_preds[,1], 2)
ERa_preds_loop <- ERa_preds 

p <- ncol(ERa_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(ERa_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=ERa_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((ERa_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(ERa_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((ERa_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(ERa_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  ERa_preds_loop <- ERa_preds_loop[,!colnames(ERa_preds_loop)==var.list[i]] # remove variable
  
}
beep(4)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#76
which(OOB.mae==min(OOB.mae))#76

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.mae_1 <- round(OOB.mae, 2)
OOB.rmse_1 <- round(OOB.rmse, 2)

which(OOB.rmse_1==min(OOB.rmse_1))#76
which(OOB.mae_1==min(OOB.mae_1))#76


# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90.ERa.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.ERa.csv", row.names = FALSE)


# Refit final model
ERa_final <- ERa %>% dplyr::select(Effect, Anthraquinone, Cotinine)

set.seed(3)
cf.final <- cforest(Effect~., data=ERa_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
ERa_final_wPred <- cbind(ERa_final, cf.final.pred.oob)

# OOB error
mean(abs(ERa_final$Effect-cf.final.pred.oob$Predicted_OOB)) ##0.254279
sqrt(mean((ERa_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) # 0.3435128 (slightly differs from loop)

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=ERa_final_wPred, pch=16)
abline(a=0, b=1)

### Unconditional ####

# Pull out response and predictors - columns 5, 7-53
ERa_preds <- ERa[, c(2, 4:86)] # original predictors
ERa_preds[,1] <- round(ERa_preds[,1], 2)
ERa_preds_loop <- ERa_preds 

p <- ncol(ERa_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(ERa_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=ERa_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((ERa_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(ERa_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((ERa_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(ERa_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=1.0) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  ERa_preds_loop <- ERa_preds_loop[,!colnames(ERa_preds_loop)==var.list[i]] # remove variable
  
}
beep(2)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#82
which(OOB.mae==min(OOB.mae))#82
var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1))#83
which(OOB.mae_1==min(OOB.mae_1))#82
var.list[which(OOB.mae_1==min(OOB.mae_1)):length(OOB.mae_1)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh100.ERa.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh100.ERa.csv", row.names = FALSE)


# Refit final model
ERa_final <- ERa %>% dplyr::select(Effect, `Tris(dichloroisopropyl)phosphate`,Anthraquinone)

set.seed(3)
cf.final <- cforest(Effect~., data=ERa_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
ERa_final_wPred <- cbind(ERa_final, cf.final.pred.oob)

# OOB error
mean(abs(ERa_final$Effect-cf.final.pred.oob$Predicted_OOB))#0.2911348 
sqrt(mean((ERa_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2))#0.3944107

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=ERa_final_wPred, pch=16)
abline(a=0, b=1)



#################ERE ########### 
# Pull out relevant columns
names(ERE)
ERE_sub <- ERE[,c(2, 4:80)]
ERE_sub[,1] <- round(ERE_sub[,1],2)
p <-ncol(ERE_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=ERE_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((ERE_sub$Effect-cf.pred)^2))#0.4385981
mean(abs(ERE_sub$Effect-cf.pred)) #0.3319864

# Plot predicted vs. observed
plot(y=cf.pred, x=ERE_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional

# cf.cpi$perTree # VI values per tree
plot(cf.cpi, type="bar")

### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
ERE_preds <- ERE[, c(2, 4:80)] # original predictors
ERE_preds[,1] <- round(ERE_preds[,1],2)
ERE_preds_loop <- ERE_preds 

p <- ncol(ERE_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(ERE_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=ERE_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((ERE_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(ERE_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((ERE_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(ERE_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  ERE_preds_loop <- ERE_preds_loop[,!colnames(ERE_preds_loop)==var.list[i]] # remove variable
  
}
beep(8)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#77
which(OOB.mae==min(OOB.mae))#77

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2) 
OOB.mae_1 <- round(OOB.mae, 2) 

which(OOB.rmse_1==min(OOB.rmse_1))#77
which(OOB.mae_1==min(OOB.mae_1))#77

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90.ERE.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.ERE.csv", row.names = FALSE)


# Refit final model
ERE_final <- ERE %>% dplyr::select(Effect,`beta-Sitosterol`)

set.seed(3)
cf.final <- cforest(Effect~., data=ERE_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
ERE_final_wPred <- cbind(ERE_final, cf.final.pred.oob)

# OOB error
mean(abs(ERE_final$Effect-cf.final.pred.oob$Predicted_OOB)) #0.2699346
sqrt(mean((ERE_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2))#0.3686934

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=ERE_final_wPred, pch=16)
abline(a=0, b=1)

# Single variable partial dependence plots
ERE_bs_pd <- partial(cf.final, pred.var="beta-Sitosterol", grid.resolution = 10)

ERE_bs_pdp <- autoplot(ERE_bs_pd, size=1.2) + theme_classic() + xlab("beta-Sitosterol") + ylab("Effect") +
  theme(text=element_text(size=20))

ggsave("ERE_cis.jpeg")

### Unconditional ####

# Pull out response and predictors - columns 5, 7-53
ERE_preds <- ERE[, c(2, 4:86)] # original predictors
ERE_preds[,1] <- round(ERE_preds[,1], 2)
ERE_preds_loop <- ERE_preds 

p <- ncol(ERE_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(ERE_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=ERE_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((ERE_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(ERE_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((ERE_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(ERE_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=1.0) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  ERE_preds_loop <- ERE_preds_loop[,!colnames(ERE_preds_loop)==var.list[i]] # remove variable
  
}
beep(1)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#82
which(OOB.mae==min(OOB.mae))#83

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2) 
OOB.mae_1 <- round(OOB.mae, 2) 

which(OOB.rmse_1==min(OOB.rmse_1))#83
which(OOB.mae_1==min(OOB.mae_1))#83

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh100.ERE.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh100.ERE.csv", row.names = FALSE)


# Refit final model
ERE_final <- ERE %>% dplyr::select(Effect, `beta-Sitosterol`)

set.seed(3)
cf.final <- cforest(Effect~., data=ERE_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
ERE_final_wPred <- cbind(ERE_final, cf.final.pred.oob)

# OOB error
mean(abs(ERE_final$Effect-cf.final.pred.oob$Predicted_OOB)) #0.2821909
sqrt(mean((ERE_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2))#0.3946387

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=ERa_final_wPred, pch=16)
abline(a=0, b=1)



#################PPARg ########### 
# Pull out relevant columns
names(PPARg)
PPARg_sub <- PPARg[,c(2, 4:80)]
PPARg_sub[,1] <-round(PPARg_sub[,1], 2)
p <-ncol(PPARg_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=PPARg_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((PPARg_sub$Effect-cf.pred)^2))#0.5841264
mean(abs(PPARg_sub$Effect-cf.pred))#0.3550139 

# Plot predicted vs. observed
plot(y=cf.pred, x=PPARg_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional


### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
PPARg_preds <- PPARg[, c(2, 4:80)] # original predictors
PPARg_preds[,1] <- round(PPARg_preds[,1],2)
PPARg_preds_loop <- PPARg_preds 

p <- ncol(PPARg_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(PPARg_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=PPARg_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((PPARg_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(PPARg_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((PPARg_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(PPARg_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  PPARg_preds_loop <- PPARg_preds_loop[,!colnames(PPARg_preds_loop)==var.list[i]] # remove variable
  
}
beep(3)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#76
which(OOB.mae==min(OOB.mae))#76

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2) 
OOB.mae_1 <- round(OOB.mae, 2) 

which(OOB.rmse_1==min(OOB.rmse_1))#76
which(OOB.mae_1==min(OOB.mae_1))#76

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90.PPARg.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.PPARg.csv", row.names = FALSE)

# Refit final model
PPARg_final <- PPARg %>% dplyr::select(Effect,Cotinine, Anthraquinone)

set.seed(3)
cf.final <- cforest(Effect~., data=PPARg_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
PPARg_final_wPred <- cbind(PPARg_final, cf.final.pred.oob)

# OOB error
mean(abs(PPARg_final$Effect-cf.final.pred.oob$Predicted_OOB))#0.3861845
sqrt(mean((PPARg_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2))#0.6425936

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=PPARg_final_wPred, pch=16)
abline(a=0, b=1)

# Single variable partial dependence plots
pparg_ccot_pd <- partial(cf.final, pred.var="Cotinine", grid.resolution = 10)
pparg_anthra_pd <- partial(cf.final, pred.var="Anthraquinone", grid.resolution = 10)

pparg_ccot_pdp <- autoplot(pparg_ccot_pd, size=1.2) + theme_classic() + xlab("Cotinine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("PPARg_trans")
pparg_anthra_pdp <- autoplot(pparg_anthra_pd, size=1.2) + theme_classic() + xlab("Anthraquinone") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("PPARg_trans")

pparg_pdps <- grid.arrange(pparg_ccot_pdp, pparg_anthra_pdp, ncol = 3)
ggsave("PPARg.jpeg", pparg_pdps, height = 15, width = 15)

### Unconditional ####

# Pull out response and predictors - columns 5, 7-53
PPARg_preds <- PPARg[, c(2, 4:86)] # original predictors
PPARg_preds[,1] <- round(PPARg_preds[,1], 2)
PPARg_preds_loop <- PPARg_preds 

p <- ncol(PPARg_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(PPARg_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=PPARg_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((PPARg_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(PPARg_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((PPARg_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(PPARg_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=1.0) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  PPARg_preds_loop <- PPARg_preds_loop[,!colnames(PPARg_preds_loop)==var.list[i]] # remove variable
  
}

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))
which(OOB.mae==min(OOB.mae))

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2) 
OOB.mae_1 <- round(OOB.mae, 2) 

which(OOB.rmse_1==min(OOB.rmse_1))#81
which(OOB.mae_1==min(OOB.mae_1))#79

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh100.PPARg.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh100.PPARg.csv", row.names = FALSE)


# Refit final model
PPARg_final <- PPARg %>% dplyr::select(Effect, Phenanthrene, Acetaminophen, Carbazole, Hexamethylenetetramine, Caffeine, Anthraquinone)

set.seed(3)
cf.final <- cforest(Effect~., data=PPARg_final, control=cforest_unbiased(mtry=2, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
PPARg_final_wPred <- cbind(PPARg_final, cf.final.pred.oob)

# OOB error
mean(abs(PPARg_final$Effect-cf.final.pred.oob$Predicted_OOB)) #0.3995853
sqrt(mean((PPARg_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) #0.6429409

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=PPARg_final_wPred, pch=16)
abline(a=0, b=1)


#################PTGER2 ########### 
# Pull out relevant columns
names(PTGER2)
View(PTGER2)
PTGER2_sub <- PTGER2[,c(2, 4:80)]
PTGER2_sub[,1] <-round(PTGER2_sub[,1], 2)
p <-ncol(PTGER2_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=PTGER2_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((PTGER2_sub$Effect-cf.pred)^2))#0.4667575
mean(abs(PTGER2_sub$Effect-cf.pred))#0.3272297 

# Plot predicted vs. observed
plot(y=cf.pred, x=PTGER2_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional


### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
PTGER2_preds <- PTGER2[, c(2, 4:80)] # original predictors
PTGER2_preds[,1] <- round(PTGER2_preds[,1],2)
PTGER2_preds_loop <- PTGER2_preds 

p <- ncol(PTGER2_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(PTGER2_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=PTGER2_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((PTGER2_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(PTGER2_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((PTGER2_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(PTGER2_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  PTGER2_preds_loop <- PTGER2_preds_loop[,!colnames(PTGER2_preds_loop)==var.list[i]] # remove variable
  
}
beep(3)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#77
which(OOB.mae==min(OOB.mae))#77

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2) 
OOB.mae_1 <- round(OOB.mae, 2) 

which(OOB.rmse_1==min(OOB.rmse_1))#76
which(OOB.mae_1==min(OOB.mae_1))#76

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90.PTGER2.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.PTGER2.csv", row.names = FALSE)


# Refit final model
PTGER2_final <- PTGER2 %>% dplyr::select(Effect,)

set.seed(3)
cf.final <- cforest(Effect~., data=PTGER2_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
PTGER2_final_wPred <- cbind(PTGER2_final, cf.final.pred.oob)

# OOB error
mean(abs(PTGER2_final$Effect-cf.final.pred.oob$Predicted_OOB))#0.3914331
sqrt(mean((PTGER2_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2))#0.6391771

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=PTGER2_final_wPred, pch=16)
abline(a=0, b=1)

#################ADRB1 ########### 
# Pull out relevant columns
names(ADRB1)
View(ADRB1)
ADRB1_sub <- ADRB1[,c(2, 4:80)]
ADRB1_sub[,1] <-round(ADRB1_sub[,1], 2)
p <-ncol(ADRB1_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=ADRB1_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((ADRB1_sub$Effect-cf.pred)^2))#0.4667575
mean(abs(ADRB1_sub$Effect-cf.pred))#0.3272297 

# Plot predicted vs. observed
plot(y=cf.pred, x=ADRB1_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional


### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
ADRB1_preds <- ADRB1[, c(2, 4:80)] # original predictors
ADRB1_preds[,1] <- round(ADRB1_preds[,1],2)
ADRB1_preds_loop <- ADRB1_preds 

p <- ncol(ADRB1_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(ADRB1_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=ADRB1_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((ADRB1_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(ADRB1_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((ADRB1_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(ADRB1_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  ADRB1_preds_loop <- ADRB1_preds_loop[,!colnames(ADRB1_preds_loop)==var.list[i]] # remove variable
  
}
beep(3)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#77
which(OOB.mae==min(OOB.mae))#77

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2) 
OOB.mae_1 <- round(OOB.mae, 2) 

which(OOB.rmse_1==min(OOB.rmse_1))#77
which(OOB.mae_1==min(OOB.mae_1))#77

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90.ADRB1.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.ADRB1.csv", row.names = FALSE)


# Refit final model - model didn't resolve
ADRB1_final <- ADRB1 %>% dplyr::select(Effect,)

set.seed(3)
cf.final <- cforest(Effect~., data=ADRB1_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
ADRB1_final_wPred <- cbind(ADRB1_final, cf.final.pred.oob)

# OOB error
mean(abs(ADRB1_final$Effect-cf.final.pred.oob$Predicted_OOB))#0.3914331
sqrt(mean((ADRB1_final$Effect-cf.final.pred.oob$Predicted_OOB)^2))#0.6391771

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=ADRB1_final_wPred, pch=16)
abline(a=0, b=1)

#################GR ########### 
# Pull out relevant columns
names(GR)
GR_sub <- GR[,c(2, 4:80)]
GR_sub[,1] <-round(GR_sub[,1], 2)
p <-ncol(GR_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=GR_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((GR_sub$Effect-cf.pred)^2))#0.1743436
mean(abs(GR_sub$Effect-cf.pred))#0.09905834 

# Plot predicted vs. observed
plot(y=cf.pred, x=GR_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional


### Loop to recursively eliminate least informative variables ####
# Pull out response and predictors - columns 5, 7-53
GR_preds <- GR[, c(2, 4:80)] # original predictors
GR_preds[,1] <- round(GR_preds[,1],2)
GR_preds_loop <- GR_preds 

p <- ncol(GR_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(GR_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=GR_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((GR_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(GR_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((GR_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(GR_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  GR_preds_loop <- GR_preds_loop[,!colnames(GR_preds_loop)==var.list[i]] # remove variable
  
}
beep(3)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#73
which(OOB.mae==min(OOB.mae))#73

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2) 
OOB.mae_1 <- round(OOB.mae, 2) 

which(OOB.rmse_1==min(OOB.rmse_1))#73
which(OOB.mae_1==min(OOB.mae_1))#77

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90.GR.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.GR.csv", row.names = FALSE)

# Refit final model
GR_final <- GR %>% dplyr::select(Effect,Metformin, Triamterene, Tramadol, "Methyl-1H-benzotriazole",  "N,N-diethyl-meta-toluamide")

set.seed(3)
cf.final <- cforest(Effect~., data=GR_final, control=cforest_unbiased(mtry=2, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
GR_final_wPred <- cbind(GR_final, cf.final.pred.oob)

# OOB error
mean(abs(GR_final$Effect-cf.final.pred.oob$Predicted_OOB))#0.09528052
sqrt(mean((GR_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2))#0.1647984

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=PPARg_final_wPred, pch=16)
abline(a=0, b=1)



#################MC1R ########### 
# Pull out relevant columns
names(MC1R)
MC1R_sub <- MC1R[,c(2, 4:80)]
MC1R_sub[,1] <-round(MC1R_sub[,1], 2)
p <-ncol(MC1R_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=MC1R_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((MC1R_sub$Effect-cf.pred)^2))#0.1936146
mean(abs(MC1R_sub$Effect-cf.pred))#0.1470548 

# Plot predicted vs. observed
plot(y=cf.pred, x=MC1R_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional


### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
MC1R_preds <- MC1R[, c(2, 4:80)] # original predictors
MC1R_preds[,1] <- round(MC1R_preds[,1],2)
MC1R_preds_loop <- MC1R_preds 

p <- ncol(MC1R_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(MC1R_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=MC1R_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((MC1R_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(MC1R_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((MC1R_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(MC1R_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  MC1R_preds_loop <- MC1R_preds_loop[,!colnames(MC1R_preds_loop)==var.list[i]] # remove variable
  
}
beep(3)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#76
which(OOB.mae==min(OOB.mae))#76

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2) 
OOB.mae_1 <- round(OOB.mae, 2) 

which(OOB.rmse_1==min(OOB.rmse_1))#76
which(OOB.mae_1==min(OOB.mae_1))#76

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90.MC1R.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.MC1R.csv", row.names = FALSE)

# Refit final model - NA didn't resolve
MC1R_final <- MC1R %>% dplyr::select(Effect,)

set.seed(3)
cf.final <- cforest(Effect~., data=MC1R_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
MC1R_final_wPred <- cbind(MC1R_final, cf.final.pred.oob)

# OOB error
mean(abs(MC1R_final$Effect-cf.final.pred.oob$Predicted_OOB))
sqrt(mean((MC1R_final$Effect-cf.final.pred.oob$Predicted_OOB)^2))

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=MC1R_final_wPred, pch=16)
abline(a=0, b=1)



#################ARE ########### 
# Pull out relevant columns
names(ARE)
ARE_sub <- ARE[,c(2, 4:80)]
ARE_sub[,1] <-round(ARE_sub[,1], 2)
p <-ncol(ARE_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=ARE_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((ARE_sub$Effect-cf.pred)^2))#0.2281842
mean(abs(ARE_sub$Effect-cf.pred))#0.1849842 

# Plot predicted vs. observed
plot(y=cf.pred, x=ARE_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional


### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
ARE_preds <- ARE[, c(2, 4:80)] # original predictors
ARE_preds[,1] <- round(ARE_preds[,1],2)
ARE_preds_loop <- ARE_preds 

p <- ncol(ARE_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(ARE_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=ARE_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((ARE_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(ARE_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((ARE_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(ARE_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  ARE_preds_loop <- ARE_preds_loop[,!colnames(ARE_preds_loop)==var.list[i]] # remove variable
  
}
beep(3)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#76
which(OOB.mae==min(OOB.mae))#77

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2) 
OOB.mae_1 <- round(OOB.mae, 2) 

which(OOB.rmse_1==min(OOB.rmse_1))#77
which(OOB.mae_1==min(OOB.mae_1))#77

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90.ARE.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.ARE.csv", row.names = FALSE)

# Refit final model
ARE_final <- ARE %>% dplyr::select(Effect, Caffeine)

set.seed(3)
cf.final <- cforest(Effect~., data=ARE_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
ARE_final_wPred <- cbind(ARE_final, cf.final.pred.oob)

# OOB error
mean(abs(ARE_final$Effect-cf.final.pred.oob$Predicted_OOB))#0.1635839
sqrt(mean((ARE_final$Effect-cf.final.pred.oob$Predicted_OOB)^2))#0.2221913

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=ARE_final_wPred, pch=16)
abline(a=0, b=1)



#################PPARa ########### 
# Pull out relevant columns
names(PPARa)
PPARa_sub <- PPARa[,c(2, 4:80)]
PPARa_sub[,1] <-round(PPARa_sub[,1], 2)
p <-ncol(PPARa_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=PPARa_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((PPARa_sub$Effect-cf.pred)^2))#0.1414394
mean(abs(PPARa_sub$Effect-cf.pred))#0.1060713 

# Plot predicted vs. observed
plot(y=cf.pred, x=PPARa_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional


### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
PPARa_preds <- PPARa[, c(2, 4:80)] # original predictors
PPARa_preds[,1] <- round(PPARa_preds[,1],2)
PPARa_preds_loop <- PPARa_preds 

p <- ncol(PPARa_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(PPARa_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=PPARa_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((PPARa_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(PPARa_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((PPARa_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(PPARa_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  PPARa_preds_loop <- PPARa_preds_loop[,!colnames(PPARa_preds_loop)==var.list[i]] # remove variable
  
}
beep(3)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#73
which(OOB.mae==min(OOB.mae))#73

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2) 
OOB.mae_1 <- round(OOB.mae, 2) 

which(OOB.rmse_1==min(OOB.rmse_1))#75
which(OOB.mae_1==min(OOB.mae_1))#76

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90.PPARa.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.PPARa.csv", row.names = FALSE)

# Refit final model
PPARa_final <- PPARa %>% dplyr::select(Effect,Cotinine, Anthraquinone)

set.seed(3)
cf.final <- cforest(Effect~., data=PPARa_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
PPARa_final_wPred <- cbind(PPARa_final, cf.final.pred.oob)

# OOB error
mean(abs(PPARa_final$Effect-cf.final.pred.oob$Predicted_OOB))#0.3861845
sqrt(mean((PPARa_final$Effect-cf.final.pred.oob$Predicted_OOB)^2))#0.6425936

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=PPARa_final_wPred, pch=16)
abline(a=0, b=1)



#################PPRE ########### 
# Pull out relevant columns
names(PPRE)
PPRE_sub <- PPRE[,c(2, 4:80)]
PPRE_sub[,1] <-round(PPRE_sub[,1], 2)
p <-ncol(PPRE_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=PPRE_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((PPRE_sub$Effect-cf.pred)^2))#0.1495917
mean(abs(PPRE_sub$Effect-cf.pred))#0.1125627 

# Plot predicted vs. observed
plot(y=cf.pred, x=PPRE_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional


### Loop to recursively eliminate least informative variables ####


# Pull out response and predictors - columns 5, 7-53
PPRE_preds <- PPRE[, c(2, 4:80)] # original predictors
PPRE_preds[,1] <- round(PPRE_preds[,1],2)
PPRE_preds_loop <- PPRE_preds 

p <- ncol(PPRE_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(PPRE_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=PPRE_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((PPRE_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(PPRE_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((PPRE_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(PPRE_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  PPRE_preds_loop <- PPRE_preds_loop[,!colnames(PPRE_preds_loop)==var.list[i]] # remove variable
  
}
beep(3)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#74
which(OOB.mae==min(OOB.mae))#73

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2) 
OOB.mae_1 <- round(OOB.mae, 2) 

which(OOB.rmse_1==min(OOB.rmse_1))#74
which(OOB.mae_1==min(OOB.mae_1))#75

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90.PPRE.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.PPRE.csv", row.names = FALSE)

# Refit final model
PPRE_final <- PPRE %>% dplyr::select(Effect,Cotinine, "Methyl-1H-benzotriazole", Acetaminophen)

set.seed(3)
cf.final <- cforest(Effect~., data=PPRE_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
PPRE_final_wPred <- cbind(PPRE_final, cf.final.pred.oob)

# OOB error
mean(abs(PPRE_final$Effect-cf.final.pred.oob$Predicted_OOB))#0.110758
sqrt(mean((PPRE_final$Effect-cf.final.pred.oob$Predicted_OOB)^2))#0.1453806

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=PPRE_final_wPred, pch=16)
abline(a=0, b=1)



#################PTGIR ########### 
# Pull out relevant columns
names(PTGIR)
PTGIR_sub <- PTGIR[,c(2, 4:80)]
PTGIR_sub[,1] <-round(PTGIR_sub[,1], 2)
p <-ncol(PTGIR_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=PTGIR_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((PTGIR_sub$Effect-cf.pred)^2))#0.1691483
mean(abs(PTGIR_sub$Effect-cf.pred))#0.1282256 

# Plot predicted vs. observed
plot(y=cf.pred, x=PTGIR_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional


### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
PTGIR_preds <- PTGIR[, c(2, 4:80)] # original predictors
PTGIR_preds[,1] <- round(PTGIR_preds[,1],2)
PTGIR_preds_loop <- PTGIR_preds 

p <- ncol(PTGIR_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(PTGIR_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=PTGIR_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((PTGIR_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(PTGIR_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((PTGIR_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(PTGIR_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  PTGIR_preds_loop <- PTGIR_preds_loop[,!colnames(PTGIR_preds_loop)==var.list[i]] # remove variable
  
}
beep(3)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#76
which(OOB.mae==min(OOB.mae))#76

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2) 
OOB.mae_1 <- round(OOB.mae, 2) 

which(OOB.rmse_1==min(OOB.rmse_1))#76
which(OOB.mae_1==min(OOB.mae_1))#76

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90.PTGIR.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.PTGIR.csv", row.names = FALSE)

# Refit final model - NA did not resolve
PTGIR_final <- PTGIR %>% dplyr::select(Effect, )

set.seed(3)
cf.final <- cforest(Effect~., data=PTGIR_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
PTGIR_final_wPred <- cbind(PTGIR_final, cf.final.pred.oob)

# OOB error
mean(abs(PTGIR_final$Effect-cf.final.pred.oob$Predicted_OOB))#
sqrt(mean((PTGIR_final$Effect-cf.final.pred.oob$Predicted_OOB)^2))#

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=PTGIR_final_wPred, pch=16)
abline(a=0, b=1)




#################RXRb ########### 
# Pull out relevant columns
names(RXRb)
RXRb_sub <- RXRb[,c(2, 4:80)]
RXRb_sub[,1] <-round(RXRb_sub[,1], 2)
p <-ncol(RXRb_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=RXRb_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((RXRb_sub$Effect-cf.pred)^2))#0.2068893
mean(abs(RXRb_sub$Effect-cf.pred))#0.1536514 

# Plot predicted vs. observed
plot(y=cf.pred, x=RXRb_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional


### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
RXRb_preds <- RXRb[, c(2, 4:80)] # original predictors
RXRb_preds[,1] <- round(RXRb_preds[,1],2)
RXRb_preds_loop <- RXRb_preds 

p <- ncol(RXRb_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(RXRb_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=RXRb_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((RXRb_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(RXRb_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((RXRb_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(RXRb_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  RXRb_preds_loop <- RXRb_preds_loop[,!colnames(RXRb_preds_loop)==var.list[i]] # remove variable
  
}
beep(3)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#76
which(OOB.mae==min(OOB.mae))#76

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2) 
OOB.mae_1 <- round(OOB.mae, 2) 

which(OOB.rmse_1==min(OOB.rmse_1))#76
which(OOB.mae_1==min(OOB.mae_1))#76

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh90.RXRb.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.RXRb.csv", row.names = FALSE)

# Refit final model
RXRb_final <- RXRb %>% dplyr::select(Effect, Anthraquinone, Acetaminophen)

set.seed(3)
cf.final <- cforest(Effect~., data=RXRb_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
RXRb_final_wPred <- cbind(RXRb_final, cf.final.pred.oob)

# OOB error
mean(abs(RXRb_final$Effect-cf.final.pred.oob$Predicted_OOB))#0.1351935
sqrt(mean((RXRb_final$Effect-cf.final.pred.oob$Predicted_OOB)^2))#0.1904145

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=RXRb_final_wPred, pch=16)
abline(a=0, b=1)


#################RIA ########### 
# Pull out relevant columns
names(RIA)
RIA_sub <- RIA[,c(2:41)]
RIA_sub[,1] <- round(RIA_sub[,1], 2)
p <-ncol(RIA_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=RIA_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((RIA_sub$Effect-cf.pred)^2))#1.534798
mean(abs(RIA_sub$Effect-cf.pred))#0.3990539

# Plot predicted vs. observed
plot(y=cf.pred, x=RIA_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional

# cf.cpi$perTree # VI values per tree
plot(cf.cpi, type="bar")


### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
RIA_preds <- RIA[, c(2:41)] # original predictors
RIA_preds[,1] <- round(RIA_preds[,1], 2)
RIA_preds_loop <- RIA_preds 

p <- ncol(RIA_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(RIA_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=RIA_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((RIA_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(RIA_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((RIA_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(RIA_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  RIA_preds_loop <- RIA_preds_loop[,!colnames(RIA_preds_loop)==var.list[i]] # remove variable
  
}
beep(8)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse)) #36
which(OOB.mae==min(OOB.mae)) #14

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #37
which(OOB.mae_1==min(OOB.mae_1)) #36

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm
saveRDS(VI.list, "cf_VI_at_iter_thresh90.RIA.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.RIA.csv", row.names = FALSE)


# Refit final model
RIA_final <- RIA %>% dplyr::select(Effect, Isophorone, Carbamazepine, "Tris(2-butoxyethyl)phosphate", Lidocaine, Desvenlafaxine, Venlafaxine)

set.seed(3)
cf.final <- cforest(Effect~., data=RIA_final, control=cforest_unbiased(mtry=2, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
RIA_final_wPred <- cbind(RIA_final, cf.final.pred.oob)

# OOB error
mean(abs(RIA_final$Effect-cf.final.pred.oob$Predicted_OOB)) ##0.401541
sqrt(mean((RIA_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) # 1.533948 (slightly differs from loop)

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=RIA_final_wPred, pch=16)
abline(a=0, b=1)

# Single variable partial dependence plots
ria_t2bep_pd <- partial(cf.final, pred.var="Tris(2-butoxyethyl)phosphate", grid.resolution = 10)
ria_iso_pd <- partial(cf.final, pred.var="Isophorone", grid.resolution = 10)
ria_carba_pd <- partial(cf.final, pred.var="Carbamazepine", grid.resolution = 10)
ria_lido_pd <- partial(cf.final, pred.var="Lidocaine", grid.resolution = 10)
ria_desven_pd <- partial(cf.final, pred.var="Desvenlafaxine", grid.resolution = 10)
ria_venla_pd <- partial(cf.final, pred.var="Venlafaxine", grid.resolution = 10)

ria_t2bep_pdp <- autoplot(ria_t2bep_pd, size=1.2) + theme_classic() + xlab("Tris(2-butoxyethyl)phosphate") + ylab("Effect") +
  theme(text=element_text(size=20))
ria_iso_pdp <- autoplot(ria_iso_pd, size=1.2) + theme_classic() + xlab("Isophorone") + ylab("Effect") +
  theme(text=element_text(size=20))
ria_carba_pdp <- autoplot(ria_carba_pd, size=1.2) + theme_classic() + xlab("Carbamazepine") + ylab("Effect") +
  theme(text=element_text(size=20))
ria_lido_pdp <- autoplot(ria_lido_pd, size=1.2) + theme_classic() + xlab("Lidocaine") + ylab("Effect") +
  theme(text=element_text(size=20))
ria_desven_pdp <- autoplot(ria_desven_pd, size=1.2) + theme_classic() + xlab("Desvenlafaxine") + ylab("Effect") +
  theme(text=element_text(size=20))
ria_venla_pdp <- autoplot(ria_venla_pd, size=1.2) + theme_classic() + xlab("Venlafaxine") + ylab("Effect") +
  theme(text=element_text(size=20))

ria <- grid.arrange(ria_t2bep_pdp,ria_iso_pdp, ria_carba_pdp, ria_lido_pdp, ria_desven_pdp, ria_venla_pdp,  ncol = 3)

ggsave("RIA_2017.jpeg", ria, height = 15, width = 15)
beep(4)

### Unconditional ####

# Pull out response and predictors - columns 5, 7-53
RIA_preds <- RIA[, c(2:48)] # original predictors
RIA_preds[,1] <- round(RIA_preds[,1], 2)
RIA_preds_loop <- RIA_preds 

p <- ncol(RIA_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(RIA_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=RIA_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((RIA_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(RIA_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((RIA_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(RIA_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=1.0) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  RIA_preds_loop <- RIA_preds_loop[,!colnames(RIA_preds_loop)==var.list[i]] # remove variable
  
}
beep(8)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#20
which(OOB.mae==min(OOB.mae))#28

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1))#45
which(OOB.mae_1==min(OOB.mae_1))#36

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh100.RIA.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh100.RIA.csv", row.names = FALSE)

# Refit final model
RIA_final <- RIA %>% dplyr::select(Effect, `Tris(2-butoxyethyl)phosphate`, `3,4-Dichlorophenyl isocyanate`, Metformin, Isophorone, Fexofenadine, Tramadol, Carbamazepine, Lidocaine, Guanylurea, Desvenlafaxine, Venlafaxine, Codeine)

set.seed(3)
cf.final <- cforest(Effect~., data=RIA_final, control=cforest_unbiased(mtry=4, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
RIA_final_wPred <- cbind(RIA_final, cf.final.pred.oob)

# OOB error
mean(abs(RIA_final$Effect-cf.final.pred.oob$Predicted_OOB))# 0.396765
sqrt(mean((RIA_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2))#1.535272

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=RIA_final_wPred, pch=16)
abline(a=0, b=1)


#################RIA_F ########### 
# Pull out relevant columns
names(RIA_F)
RIA_F_sub <- RIA_F[,c(2:41)]
RIA_F_sub[,1] <- round(RIA_F_sub[,1], 2)
p <-ncol(RIA_F_sub)-1

# cforest - all variables
set.seed(3) 
cf.all <- cforest(Effect~., data=RIA_F_sub, control=cforest_unbiased(mtry=ceiling(p/3), ntree=5000))
cf.pred <- predict(cf.all, OOB=T)
sqrt(mean((RIA_F_sub$Effect-cf.pred)^2))#2.74432
mean(abs(RIA_F_sub$Effect-cf.pred))#1.935423

# Plot predicted vs. observed
plot(y=cf.pred, x=RIA_F_sub$Effect)
abline(a=0, b=1)

# Variable importance for full model

# Unconditional variable importance (threshold=1)
set.seed(3) 
cf.upi <- permimp(cf.all, conditional=TRUE, threshold=1, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.upi$values, decreasing=T)) # CF, unconditional

# Conditional variable importance (threshold=0.9)
set.seed(3) 
cf.cpi <- permimp(cf.all, conditional=TRUE, threshold=0.90, thresholdDiagnostics = TRUE)
as.matrix(sort(cf.cpi$values, decreasing=T)) # CF, conditional

# cf.cpi$perTree # VI values per tree
plot(cf.cpi, type="bar")


### Loop to recursively eliminate least informative variables ####

# Pull out response and predictors - columns 5, 7-53
RIA_F_preds <- RIA_F[, c(2:41)] # original predictors
RIA_F_preds[,1] <- round(RIA_F_preds[,1], 2)
RIA_F_preds_loop <- RIA_F_preds 

p <- ncol(RIA_F_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(RIA_F_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=RIA_F_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((RIA_F_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(RIA_F_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((RIA_F_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(RIA_F_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=0.9) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  RIA_F_preds_loop <- RIA_F_preds_loop[,!colnames(RIA_F_preds_loop)==var.list[i]] # remove variable
  
}
beep(8)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse)) #39
which(OOB.mae==min(OOB.mae)) #39

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]
# "Tramadol"          "Desvenlafaxine"  

#round
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1)) #40
which(OOB.mae_1==min(OOB.mae_1)) #39

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm
saveRDS(VI.list, "cf_VI_at_iter_thresh90.RIA_F.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh90.RIA_F.csv", row.names = FALSE)


# Refit final model
RIA_F_final <- RIA_F %>% dplyr::select(Effect,Desvenlafaxine, Tramadol)

set.seed(3)
cf.final <- cforest(Effect~., data=RIA_F_final, control=cforest_unbiased(mtry=1, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
RIA_F_final_wPred <- cbind(RIA_F_final, cf.final.pred.oob)

# OOB error
mean(abs(RIA_F_final$Effect-cf.final.pred.oob$Predicted_OOB)) ##1.907478
sqrt(mean((RIA_F_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2)) #2.688791

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=RIA_F_final_wPred, pch=16)
abline(a=0, b=1)

# Single variable partial dependence plots
ria_f_tramadol_pd <- partial(cf.final, pred.var="Tramadol", grid.resolution = 10)
ria_f_desven_pd <- partial(cf.final, pred.var="Desvenlafaxine", grid.resolution = 10)

ria_f_tramadol_pdp <- autoplot(ria_f_tramadol_pd, size=1.2) + theme_classic() + xlab("Tramadol") + ylab("Effect") +
  theme(text=element_text(size=20))
ria_f_desven_pdp <- autoplot(ria_f_desven_pd, size=1.2) + theme_classic() + xlab("Desvenlafaxine") + ylab("Effect") +
  theme(text=element_text(size=20))

ria_f <- grid.arrange(ria_f_tramadol_pdp,ria_f_desven_pdp, ncol = 3)

ggsave("RIA_F_2017.jpeg", ria_f, height = 15, width = 15)

### Unconditional ####

# Pull out response and predictors - columns 5, 7-53
RIA_preds <- RIA[, c(2:48)] # original predictors
RIA_preds[,1] <- round(RIA_preds[,1], 2)
RIA_preds_loop <- RIA_preds 

p <- ncol(RIA_preds)-1

# Save OOB error, variable importance
VI.list <- NULL
var.list <- rep(NA,p)

OOB.rmse <- rep(NA,p)
OOB.mae <- rep(NA,p)

train.rmse <- rep(NA,p)
train.mae <- rep(NA,p)

set.seed(3) # Set seed for reproducibility

for(i in 1:p){
  print(i)
  
  nump <- ncol(RIA_preds_loop)-1 # Number predictors
  
  set.seed(3) 
  cf <- cforest(Effect~., data=RIA_preds_loop, control=cforest_unbiased(mtry=ceiling(nump/3), ntree=5000))
  cf.pred <- predict(cf, OOB=T)
  cf.pred.tr <- predict(cf, OOB=F)
  
  # OOB error
  OOB.rmse[i] <- sqrt(mean((RIA_preds$Effect-cf.pred)^2)) # OOB rmse
  OOB.mae[i] <- mean(abs(RIA_preds$Effect-cf.pred)) # oob mae
  
  # Training error
  train.rmse[i] <- sqrt(mean((RIA_preds$Effect-cf.pred.tr)^2)) # training rmse
  train.mae[i] <- mean(abs(RIA_preds$Effect-cf.pred.tr)) #  training mae
  
  
  # Variable importance
  set.seed(3) 
  cf.cpi <- permimp(cf, conditional=TRUE, threshold=1.0) # set threshold to 1 for unconditional
  
  VI.list[[i]] <- as.matrix(sort(cf.cpi$values, decreasing=F))
  var.list[i] <- row.names(VI.list[[i]])[1] # Least informative variable to remove
  
  
  RIA_preds_loop <- RIA_preds_loop[,!colnames(RIA_preds_loop)==var.list[i]] # remove variable
  
}
beep(8)

# Plot OOB error - minimum is the best subset of predictors
plot(OOB.rmse, xlab="Iteration", type='l')
points(OOB.rmse, pch=16)
plot(OOB.mae, xlab="Iteration", type='l')
points(OOB.mae, pch=16)
# training error (not to be used for optimizing number predictors)
plot(train.rmse, xlab="Iteration", type='l')
points(train.rmse, pch=16)

which(OOB.rmse==min(OOB.rmse))#20
which(OOB.mae==min(OOB.mae))#28

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

#round
OOB.rmse_1 <- round(OOB.rmse, 2)
OOB.mae_1 <- round(OOB.mae, 2)

which(OOB.rmse_1==min(OOB.rmse_1))#45
which(OOB.mae_1==min(OOB.mae_1))#36

var.list[which(OOB.mae==min(OOB.mae)):length(OOB.mae)]

# Save output - name files in a way that lets you know what differs between different runs of the algorithm

saveRDS(VI.list, "cf_VI_at_iter_thresh100.RIA.rds") # R object (list) with the variable importances at each iteration of the algorithm

RFE_info <- data.frame(Worst_Var=var.list, OOB_rmse=OOB.rmse, OOB_mae=OOB.mae, Train_rmse=train.rmse, Train_mae=train.mae)

write.csv(RFE_info, "cf_RFE_info_thresh100.RIA.csv", row.names = FALSE)

# Refit final model
RIA_final <- RIA %>% dplyr::select(Effect, `Tris(2-butoxyethyl)phosphate`, `3,4-Dichlorophenyl isocyanate`, Metformin, Isophorone, Fexofenadine, Tramadol, Carbamazepine, Lidocaine, Guanylurea, Desvenlafaxine, Venlafaxine, Codeine)

set.seed(3)
cf.final <- cforest(Effect~., data=RIA_final, control=cforest_unbiased(mtry=4, ntree=5000))

# OOB predictions
cf.final.pred.oob <- data.frame(predict(cf.final, OOB=T)) %>% rename(Predicted_OOB=Effect)
RIA_final_wPred <- cbind(RIA_final, cf.final.pred.oob)

# OOB error
mean(abs(RIA_final$Effect-cf.final.pred.oob$Predicted_OOB))# 0.396765
sqrt(mean((RIA_preds$Effect-cf.final.pred.oob$Predicted_OOB)^2))#1.535272

# Predicted (OOB) vs. observed
plot(Predicted_OOB~Effect, data=RIA_final_wPred, pch=16)
abline(a=0, b=1)




#### final pd plots####
#estrogenic####
#RIA
RIA_final <- RIA %>% dplyr::select(Effect, Isophorone, Carbamazepine, "Tris(2-butoxyethyl)phosphate", Lidocaine, Desvenlafaxine, Venlafaxine)
set.seed(3)
cf.final <- cforest(Effect~., data=RIA_final, control=cforest_unbiased(mtry=2, ntree=5000))
ria_t2bep_pd <- partial(cf.final, pred.var="Tris(2-butoxyethyl)phosphate", grid.resolution = 10)
ria_iso_pd <- partial(cf.final, pred.var="Isophorone", grid.resolution = 10)
ria_carba_pd <- partial(cf.final, pred.var="Carbamazepine", grid.resolution = 10)
ria_lido_pd <- partial(cf.final, pred.var="Lidocaine", grid.resolution = 10)
ria_desven_pd <- partial(cf.final, pred.var="Desvenlafaxine", grid.resolution = 10)
ria_venla_pd <- partial(cf.final, pred.var="Venlafaxine", grid.resolution = 10)

ria_t2bep_pdp <- autoplot(ria_t2bep_pd, size=1.2) + theme_classic() + xlab("Tris(2-butoxyethyl)phosphate") + ylab("Effect") +
  theme(text=element_text(size=20)) + ggtitle("RIA_M")
ria_iso_pdp <- autoplot(ria_iso_pd, size=1.2) + theme_classic() + xlab("Isophorone") + ylab("Effect") +
  theme(text=element_text(size=20)) + ggtitle("RIA_M")
ria_carba_pdp <- autoplot(ria_carba_pd, size=1.2) + theme_classic() + xlab("Carbamazepine") + ylab("Effect") +
  theme(text=element_text(size=20)) + ggtitle("RIA_M")
ria_lido_pdp <- autoplot(ria_lido_pd, size=1.2) + theme_classic() + xlab("Lidocaine") + ylab("Effect") +
  theme(text=element_text(size=20)) + ggtitle("RIA_M")
ria_desven_pdp <- autoplot(ria_desven_pd, size=1.2) + theme_classic() + xlab("Desvenlafaxine") + ylab("Effect") +
  theme(text=element_text(size=20)) + ggtitle("RIA_M")
ria_venla_pdp <- autoplot(ria_venla_pd, size=1.2) + theme_classic() + xlab("Venlafaxine") + ylab("Effect") +
  theme(text=element_text(size=20)) + ggtitle("RIA_M")

RIA_F_final <- RIA_F %>% dplyr::select(Effect,Desvenlafaxine, Tramadol)
set.seed(3)
cf.final <- cforest(Effect~., data=RIA_F_final, control=cforest_unbiased(mtry=1, ntree=5000))
ria_f_tramadol_pd <- partial(cf.final, pred.var="Tramadol", grid.resolution = 10)
ria_f_desven_pd <- partial(cf.final, pred.var="Desvenlafaxine", grid.resolution = 10)
ria_f_tramadol_pdp <- autoplot(ria_f_tramadol_pd, size=1.2) + theme_classic() + xlab("Tramadol") + ylab("Effect") +
  theme(text=element_text(size=20)) + ggtitle("RIA_F")
ria_f_desven_pdp <- autoplot(ria_f_desven_pd, size=1.2) + theme_classic() + xlab("Desvenlafaxine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("RIA_F")

#ERE
ERE_final <- ERE %>% dplyr::select(Effect,`beta-Sitosterol`)
set.seed(3)
cf.final <- cforest(Effect~., data=ERE_final, control=cforest_unbiased(mtry=1, ntree=5000))
ERE_bs_pd <- partial(cf.final, pred.var="beta-Sitosterol", grid.resolution = 10)
ERE_bs_pdp <- autoplot(ERE_bs_pd, size=1.2) + theme_classic() + xlab("beta-Sitosterol") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("ERE_cis")

#ERa
ERa_final <- ERa %>% dplyr::select(Effect, Anthraquinone, Cotinine)
set.seed(3)
cf.final <- cforest(Effect~., data=ERa_final, control=cforest_unbiased(mtry=1, ntree=5000))
era_anthra_pd <- partial(cf.final, pred.var="Anthraquinone", grid.resolution = 10)
era_anthra_pdp <- autoplot(era_anthra_pd, size=1.2) + theme_classic() + xlab("Anthraquinone") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("ERa_trans")


#t47
t47_final <- t47.allyears %>% dplyr::select(Effect,`beta-Sitosterol`, Cholesterol, Dextromethorphan, Metoprolol,
                                            `Methyl-1H-benzotriazole`, Bupropion,
                                            Cotinine, `3-beta-Coprostanol`, "Hexahydrohexamethylcyclopentabenzopyran (HHCB)",
                                            Camphor, Tramadol)
set.seed(3)
cf.final <- cforest(Effect~., data=t47_final, control=cforest_unbiased(mtry=4, ntree=5000))

t47_bss_pd <- partial(cf.final, pred.var="beta-Sitosterol", grid.resolution = 10)
t47_chol_pd <- partial(cf.final, pred.var="Cholesterol", grid.resolution = 10)
t47_dex_pd <- partial(cf.final, pred.var="Dextromethorphan", grid.resolution = 10)
t47_m1hbt_pd <- partial(cf.final, pred.var="Methyl-1H-benzotriazole", grid.resolution = 10)

t47_bss_pdp <- autoplot(t47_bss_pd, size=1.2) + theme_classic() + xlab("beta-Sitosterol") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("T47D-Kbluc")
t47_chol_pdp <- autoplot(t47_chol_pd, size=1.2) + theme_classic() + xlab("Cholesterol") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("T47D-Kbluc")
t47_dex_pdp <- autoplot(t47_dex_pd, size=1.2) + theme_classic() + xlab("Dextromethorphan") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("T47D-Kbluc")
t47_m1hbt_pdp <- autoplot(t47_m1hbt_pd, size=1.2) + theme_classic() + xlab("Methyl-1H-benzotriazole") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("T47D-Kbluc")
#final estrogen plot
estrogen <- grid.arrange(ria_t2bep_pdp,ria_iso_pdp, ria_carba_pdp, ria_lido_pdp, ria_desven_pdp, ria_venla_pdp, 
                         ria_f_tramadol_pdp, ria_f_desven_pdp, ERE_bs_pdp, 
                         era_anthra_pdp,
                         t47_bss_pdp, t47_chol_pdp, 
                         t47_dex_pdp, t47_m1hbt_pdp,ncol = 4)

ggsave("Estrogenic_pdp.jpeg", estrogen, height = 20, width = 20)

#xenobiotic - liver ####
#CYP1A1
cyp_liv_final <- cyp_1a1_2017_liver %>% dplyr::select(Effect, Anthraquinone, Phenanthrene, Carbazole,
                                                      Fluoranthene, "Benzo[a]pyrene", "Methyl-1H-benzotriazole",
                                                      Pyrene, Acetaminophen, Desvenlafaxine, Cotinine, 
                                                      "1-Methylnaphthalene", "N,N-diethyl-meta-toluamide", "4-tert-Octylphenol monoethoxylate",
                                                      Isophorone, "5-Methyl-1H-benzotriazole", Carbaryl, Lidocaine, Caffeine, 
                                                      Carbamazepine, "3,4-Dichlorophenyl isocyanate", Metformin, "Bisphenol A") 

set.seed(3)
cf.final <- cforest(Effect~., data=cyp_liv_final, control=cforest_unbiased(mtry=7, ntree=5000))

cyp1a1_liver_pd_phenanthrene <- partial(cf.final, pred.var="Phenanthrene", grid.resolution = 10)
cyp1a1_liver_pd_anthraquinone <- partial(cf.final, pred.var="Anthraquinone", grid.resolution = 10)
cyp1a1_liver_pd_carbazole <- partial(cf.final, pred.var="Carbazole", grid.resolution = 10)
cyp1a1_liver_pd_Fluoranthene <- partial(cf.final, pred.var="Fluoranthene", grid.resolution = 10)
cyp1a1_liver_pd_BaP <- partial(cf.final, pred.var="Benzo[a]pyrene", grid.resolution = 10)
cyp1a1_liver_pd_m1hbt <- partial(cf.final, pred.var="Methyl-1H-benzotriazole", grid.resolution = 10)
cyp1a1_liver_pd_Pyrene <- partial(cf.final, pred.var="Pyrene", grid.resolution = 10)
cyp1a1_liver_pd_Acetaminophen <- partial(cf.final, pred.var="Acetaminophen", grid.resolution = 10)
cyp1a1_liver_pd_Desvenlafaxine <- partial(cf.final, pred.var="Desvenlafaxine", grid.resolution = 10)
cyp1a1_liver_pd_Cotinine <- partial(cf.final, pred.var="Cotinine", grid.resolution = 10)
cyp1a1_liver_pd_1mnap <- partial(cf.final, pred.var="1-Methylnaphthalene", grid.resolution = 10)
cyp1a1_liver_pd_deet <- partial(cf.final, pred.var="N,N-diethyl-meta-toluamide", grid.resolution = 10)
cyp1a1_liver_pd_4tom <- partial(cf.final, pred.var="4-tert-Octylphenol monoethoxylate", grid.resolution = 10)
cyp1a1_liver_pd_Isophorone <- partial(cf.final, pred.var="Isophorone", grid.resolution = 10)
cyp1a1_liver_pd_5m1hbt <- partial(cf.final, pred.var="5-Methyl-1H-benzotriazole", grid.resolution = 10)
cyp1a1_liver_pd_Carbaryl <- partial(cf.final, pred.var="Carbaryl", grid.resolution = 10)
cyp1a1_liver_pd_Lidocaine <- partial(cf.final, pred.var="Lidocaine", grid.resolution = 10)
cyp1a1_liver_pd_Caffeine <- partial(cf.final, pred.var="Caffeine", grid.resolution = 10)
cyp1a1_liver_pd_Carbamazepine <- partial(cf.final, pred.var="Carbamazepine", grid.resolution = 10)
cyp1a1_liver_pd_34di <- partial(cf.final, pred.var="3,4-Dichlorophenyl isocyanate", grid.resolution = 10)
cyp1a1_liver_pd_Metformin <- partial(cf.final, pred.var="Metformin", grid.resolution = 10)
cyp1a1_liver_pd_BPA <- partial(cf.final, pred.var="Bisphenol A", grid.resolution = 10)

cyp1a1_liver_pdp_phenanthrene <- autoplot(cyp1a1_liver_pd_phenanthrene, size=1.2) + theme_classic() + xlab("Phenanthrene") + ylab("Effect") +
  theme(text=element_text(size=20)) + ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_anthraquinone <- autoplot(cyp1a1_liver_pd_anthraquinone, size=1.2) + theme_classic() + xlab("Anthraquinone") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_carbazole <- autoplot(cyp1a1_liver_pd_carbazole, size=1.2) + theme_classic() + xlab("Carbazole") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_Fluoranthene <- autoplot(cyp1a1_liver_pd_Fluoranthene, size=1.2) + theme_classic() + xlab("Fluoranthene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_BaP <- autoplot(cyp1a1_liver_pd_BaP, size=1.2) + theme_classic() + xlab("Benzo[a]pyrene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_m1hbt <- autoplot(cyp1a1_liver_pd_m1hbt, size=1.2) + theme_classic() + xlab("Methyl-1H-benzotriazole") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_Pyrene <- autoplot(cyp1a1_liver_pd_Pyrene, size=1.2) + theme_classic() + xlab("Pyrene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_Acetaminophen <- autoplot(cyp1a1_liver_pd_Acetaminophen, size=1.2) + theme_classic() + xlab("Acetaminophen") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_Desvenlafaxine <- autoplot(cyp1a1_liver_pd_Desvenlafaxine, size=1.2) + theme_classic() + xlab("Desvenlafaxine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_Cotinine <- autoplot(cyp1a1_liver_pd_Cotinine, size=1.2) + theme_classic() + xlab("Cotinine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_1mnap <- autoplot(cyp1a1_liver_pd_1mnap, size=1.2) + theme_classic() + xlab("1-Methylnaphthalene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_deet <- autoplot(cyp1a1_liver_pd_deet, size=1.2) + theme_classic() + xlab("N,N-diethyl-meta-toluamide") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_4tom <- autoplot(cyp1a1_liver_pd_4tom, size=1.2) + theme_classic() + xlab("4-tert-Octylphenol monoethoxylate") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_Isophorone <- autoplot(cyp1a1_liver_pd_Isophorone, size=1.2) + theme_classic() + xlab("Isophorone") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_5m1hbt <- autoplot(cyp1a1_liver_pd_5m1hbt, size=1.2) + theme_classic() + xlab("5-Methyl-1H-benzotriazole") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_Carbaryl <- autoplot(cyp1a1_liver_pd_Carbaryl, size=1.2) + theme_classic() + xlab("Carbaryl") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_Lidocaine <- autoplot(cyp1a1_liver_pd_Lidocaine, size=1.2) + theme_classic() + xlab("Lidocaine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_Caffeine <- autoplot(cyp1a1_liver_pd_Caffeine, size=1.2) + theme_classic() + xlab("Caffeine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_Carbamazepine <- autoplot(cyp1a1_liver_pd_Carbamazepine, size=1.2) + theme_classic() + xlab("Carbamazepine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_34di <- autoplot(cyp1a1_liver_pd_34di, size=1.2) + theme_classic() + xlab("3,4-Dichlorophenyl isocyanate") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_Metformin <- autoplot(cyp1a1_liver_pd_Metformin, size=1.2) + theme_classic() + xlab("Metformin") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")
cyp1a1_liver_pdp_BPA <- autoplot(cyp1a1_liver_pd_BPA, size=1.2) + theme_classic() + xlab("Bisphenol A") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")


#CYP1A1 2018

cyp_1a1_2018_final <- cyp1a1_2018 %>% dplyr::select(Effect,Pyrene, Triamterene, Ranitidine,
                                                    Venlafaxine, "beta-Sitosterol", Metformin, 
                                                    Metolachlor,"1-Methylnaphthalene",  Dextromethorphan,
                                                    Fluoranthene, Atrazine,Metoprolol,
                                                    "N,N-diethyl-meta-toluamide", Anthraquinone,`Benzo[a]pyrene`, 
                                                    Acetaminophen, Cholesterol, Phenanthrene, Cotinine, Caffeine,
                                                    `Tributyl phosphate`, `Methyl-1H-benzotriazole`)

set.seed(3)
cf.final <- cforest(Effect~., data=cyp_1a1_2018_final, control=cforest_unbiased(mtry=7, ntree=5000))

cyp1a12018_pyrene_pd <- partial(cf.final, pred.var="Pyrene", grid.resolution = 10)
cyp1a12018_pyrene_pdp <- autoplot(cyp1a12018_pyrene_pd, size=1.2) + theme_classic() + xlab("Pyrene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_triam_pd <- partial(cf.final, pred.var="Triamterene", grid.resolution = 10)
cyp1a12018_triam_pdp <- autoplot(cyp1a12018_triam_pd, size=1.2) + theme_classic() + xlab("Triamterene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_Ranitidine_pd <- partial(cf.final, pred.var="Ranitidine", grid.resolution = 10)
cyp1a12018_Ranitidine_pdp <- autoplot(cyp1a12018_Ranitidine_pd, size=1.2) + theme_classic() + xlab("Ranitidine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_venlafaxine_pd <- partial(cf.final, pred.var="Venlafaxine", grid.resolution = 10)
cyp1a12018_venlafaxine_pdp <- autoplot(cyp1a12018_venlafaxine_pd, size=1.2) + theme_classic() + xlab("Venlafaxine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_betasito_pd <- partial(cf.final, pred.var="beta-Sitosterol", grid.resolution = 10)
cyp1a12018_betasito_pdp <- autoplot(cyp1a12018_betasito_pd, size=1.2) + theme_classic() + xlab("beta-Sitosterol") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_metformin_pd <- partial(cf.final, pred.var="Metformin", grid.resolution = 10)
cyp1a12018_metformin_pdp <- autoplot(cyp1a12018_metformin_pd, size=1.2) + theme_classic() + xlab("Metformin") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_metolachlor_pd <- partial(cf.final, pred.var="Metolachlor", grid.resolution = 10)
cyp1a12018_metolachlor_pdp <- autoplot(cyp1a12018_metolachlor_pd, size=1.2) + theme_classic() + xlab("Metolachlor") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_1methnap_pd <- partial(cf.final, pred.var="1-Methylnaphthalene", grid.resolution = 10)
cyp1a12018_1methnap_pdp <- autoplot(cyp1a12018_1methnap_pd, size=1.2) + theme_classic() + xlab("1-Methylnaphthalene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_dexto_pd <- partial(cf.final, pred.var="Fluoranthene", grid.resolution = 10)
cyp1a12018_dexto_pdp <- autoplot(cyp1a12018_dexto_pd, size=1.2) + theme_classic() + xlab("Fluoranthene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_fluor_pd <- partial(cf.final, pred.var="Fluoranthene", grid.resolution = 10)
cyp1a12018_fluor_pdp <- autoplot(cyp1a12018_fluor_pd, size=1.2) + theme_classic() + xlab("Fluoranthene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_atz_pd <- partial(cf.final, pred.var="Atrazine", grid.resolution = 10)
cyp1a12018_atz_pdp <- autoplot(cyp1a12018_atz_pd, size=1.2) + theme_classic() + xlab("Atrazine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_Metoprolol_pd <- partial(cf.final, pred.var="Metoprolol", grid.resolution = 10)
cyp1a12018_Metoprolol_pdp <- autoplot(cyp1a12018_Metoprolol_pd, size=1.2) + theme_classic() + xlab("Metoprolol") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_deet_pd <- partial(cf.final, pred.var="N,N-diethyl-meta-toluamide", grid.resolution = 10)
cyp1a12018_deet_pdp <- autoplot(cyp1a12018_deet_pd, size=1.2) + theme_classic() + xlab("N,N-diethyl-meta-toluamide") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_anthraquinone_pd <- partial(cf.final, pred.var="Anthraquinone", grid.resolution = 10)
cyp1a12018_anthraquinone_pdp <- autoplot(cyp1a12018_anthraquinone_pd, size=1.2) + theme_classic() + xlab("Phenanthrene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_bap_pd <- partial(cf.final, pred.var="Benzo[a]pyrene", grid.resolution = 10)
cyp1a12018_bap_pdp <- autoplot(cyp1a12018_bap_pd, size=1.2) + theme_classic() + xlab("Benzo[a]pyrene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_Acetaminophen_pd <- partial(cf.final, pred.var="Acetaminophen", grid.resolution = 10)
cyp1a12018_Acetaminophen_pdp <- autoplot(cyp1a12018_Acetaminophen_pd, size=1.2) + theme_classic() + xlab("Acetaminophen") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_cholesterol_pd <- partial(cf.final, pred.var="Dextromethorphan", grid.resolution = 10)
cyp1a12018_cholesterol_pdp <- autoplot(cyp1a12018_cholesterol_pd, size=1.2) + theme_classic() + xlab("Dextromethorphan") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_phen_pd <- partial(cf.final, pred.var="Phenanthrene", grid.resolution = 10)
cyp1a12018_phen_pdp <- autoplot(cyp1a12018_phen_pd, size=1.2) + theme_classic() + xlab("Phenanthrene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_cot_pd <- partial(cf.final, pred.var="Cotinine", grid.resolution = 10)
cyp1a12018_cot_pdp <- autoplot(cyp1a12018_cot_pd, size=1.2) + theme_classic() + xlab("Cotinine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_caffeine_pd <- partial(cf.final, pred.var="Caffeine", grid.resolution = 10)
cyp1a12018_caffeine_pdp <- autoplot(cyp1a12018_caffeine_pd, size=1.2) + theme_classic() + xlab("Caffeine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_m1hbt_pd <- partial(cf.final, pred.var="Methyl-1H-benzotriazole", grid.resolution = 10)
cyp1a12018_m1hbt_pdp <- autoplot(cyp1a12018_m1hbt_pd, size=1.2) + theme_classic() + xlab("Methyl-1H-benzotriazole") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

cyp1a12018_tbp_pd <- partial(cf.final, pred.var="Tributyl phosphate", grid.resolution = 10)
cyp1a12018_tbp_pdp <- autoplot(cyp1a12018_tbp_pd, size=1.2) + theme_classic() + xlab("Tributyl phosphate") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2018")

# Refit final model
CYP3A_liv_final <- cyp_3A_liver %>% dplyr::select(Effect, Indole, Carbazole)

set.seed(3)
cf.final <- cforest(Effect~., data=CYP3A_liv_final, control=cforest_unbiased(mtry=1, ntree=5000))

cf.partial1 <- partial(cf.final, pred.var="Indole", grid.resolution = 10)
cf.partial2 <- partial(cf.final, pred.var="Carbazole", grid.resolution = 10)

cyp3a_liv_indole <- autoplot(cf.partial1, size=1.2) + theme_classic() + xlab("Indole") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 3A 2017")
cyp3a_liv_carbazole <- autoplot(cf.partial2, size=1.2) + theme_classic() + xlab("Carbazole") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 3A 2017")

#UGT1A1
ugt_1a1_liver_final <- ugt_1a1_liver %>% dplyr::select(Effect, Fexofenadine, Isophorone)
set.seed(3)
cf.final <- cforest(Effect~., data=ugt_1a1_liver_final, control=cforest_unbiased(mtry=1, ntree=5000))

cf.partial1 <- partial(cf.final, pred.var="Fexofenadine", grid.resolution = 10)
cf.partial2 <- partial(cf.final, pred.var="Isophorone", grid.resolution = 10)

ugt1a1_liv_fexo <- autoplot(cf.partial1, size=1.2) + theme_classic() + xlab("Fexofenadine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1 2017")
ugt1a1_liv_iso <- autoplot(cf.partial2, size=1.2) + theme_classic() + xlab("Isophorone") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1 2017")


#final liver figure
liver.xeno <- grid.arrange(cyp1a1_liver_pdp_phenanthrene, cyp1a1_liver_pdp_anthraquinone,
                           cyp1a1_liver_pdp_carbazole, cyp1a1_liver_pdp_Fluoranthene, cyp1a1_liver_pdp_BaP,
                           cyp1a1_liver_pdp_m1hbt, cyp1a1_liver_pdp_Pyrene, cyp1a1_liver_pdp_Acetaminophen,
                           cyp1a1_liver_pdp_Desvenlafaxine, cyp1a1_liver_pdp_Cotinine, cyp1a1_liver_pdp_1mnap,
                           cyp1a1_liver_pdp_deet, cyp1a1_liver_pdp_4tom, cyp1a1_liver_pdp_Isophorone,
                           cyp1a1_liver_pdp_5m1hbt, cyp1a1_liver_pdp_Carbaryl, cyp1a1_liver_pdp_Lidocaine,
                           cyp1a1_liver_pdp_Caffeine, cyp1a1_liver_pdp_Carbamazepine, cyp1a1_liver_pdp_34di,
                           cyp1a1_liver_pdp_Metformin, cyp1a1_liver_pdp_BPA, 
                           cyp1a12018_betasito_pdp, cyp1a12018_pyrene_pdp,
                           cyp1a12018_metformin_pdp, cyp1a12018_metolachlor_pdp, cyp1a12018_venlafaxine_pdp,
                           cyp1a12018_1methnap_pdp, cyp1a12018_fluor_pdp, cyp1a12018_dexto_pdp, cyp1a12018_cholesterol_pdp,
                           cyp1a12018_atz_pdp, cyp1a12018_deet_pdp, cyp1a12018_Metoprolol_pdp, cyp1a12018_Acetaminophen_pdp,
                           cyp1a12018_m1hbt_pdp, cyp1a12018_anthraquinone_pdp, cyp1a12018_caffeine_pdp, cyp1a12018_tbp_pdp,
                           cyp1a12018_bap_pdp, cyp1a12018_phen_pdp, cyp1a12018_cot_pdp,cyp1a12018_triam_pdp, cyp1a12018_Ranitidine_pdp,
                           cyp3a_liv_indole, cyp3a_liv_carbazole,
                           ugt1a1_liv_fexo,
                           ugt1a1_liv_iso, ncol = 4)

ggsave("Liver_Xeno.jpeg", liver.xeno, height = 30, width = 20)


#xenobiotic - intestine ####
#CYP 1A
cyp_int_final <- CYP1A1.intestine %>% dplyr::select(Effect, Pyrene)
set.seed(3)
cf.final <- cforest(Effect~., data=cyp_int_final, control=cforest_unbiased(mtry=1, ntree=5000))
cyp1a1_int_pd_pyrene <- partial(cf.final, pred.var="Pyrene", grid.resolution = 10)
cyp1a1_int_pdp_pyrene <- autoplot(cyp1a1_int_pd_pyrene, size=1.2) + theme_classic() + xlab("Pyrene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 1A1 2017")

#CYP 3A
CYP_3A_intestine_final <- CYP_3A_intestine %>% dplyr::select(Effect, "Methyl-1H-benzotriazole")
set.seed(3)
cf.final <- cforest(Effect~., data=CYP_3A_intestine_final, control=cforest_unbiased(mtry=1, ntree=5000))

cyp3a_int_pd <- partial(cf.final, pred.var="Methyl-1H-benzotriazole", grid.resolution = 10)

cyp3a_int_pdp <- autoplot(cyp3a_int_pd, size=1.2) + theme_classic() + xlab("Methyl-1H-benzotriazole") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 3A 2017")


#CYP 2AD6
cyp_2ad6_2017_final <- cyp_2ad6_2017 %>% dplyr::select(Effect, "N,N-diethyl-meta-toluamide",Carbamazepine, Cholesterol,
                                                       Desvenlafaxine, Lidocaine, Metformin,
                                                       Tramadol, Venlafaxine, Metolachlor, 
                                                       Fexofenadine, "3,4-Dichlorophenyl isocyanate", Atrazine)

set.seed(3)
cf.final <- cforest(Effect~., data=cyp_2ad6_2017_final, control=cforest_unbiased(mtry=4, ntree=5000))

cyp2ad6_atz_pd <- partial(cf.final, pred.var="Atrazine", grid.resolution = 10)
cyp2ad6_dichloro_pd <- partial(cf.final, pred.var="3,4-Dichlorophenyl isocyanate", grid.resolution = 10)
cyp2ad6_carbamazepine_pd <- partial(cf.final, pred.var="Carbamazepine", grid.resolution = 10)
cyp2ad6_choles_pd <- partial(cf.final, pred.var="Cholesterol", grid.resolution = 10)
cyp2ad6_desven_pd <- partial(cf.final, pred.var="Desvenlafaxine", grid.resolution = 10)
cyp2ad6_fexo_pd <- partial(cf.final, pred.var="Fexofenadine", grid.resolution = 10)
cyp2ad6_lidocaine_pd <- partial(cf.final, pred.var="Lidocaine", grid.resolution = 10)
cyp2ad6_metformin_pd <- partial(cf.final, pred.var="Metformin", grid.resolution = 10)
cyp2ad6_tramadol_pd <- partial(cf.final, pred.var="Tramadol", grid.resolution = 10)
cyp2ad6_deet_pd <- partial(cf.final, pred.var="N,N-diethyl-meta-toluamide", grid.resolution = 10)
cyp2ad6_venla_pd <- partial(cf.final, pred.var="Venlafaxine", grid.resolution = 10)
cyp2ad6_metola_pd <- partial(cf.final, pred.var="Metolachlor", grid.resolution = 10)

cyp2ad6_atz_pdp <- autoplot(cyp2ad6_atz_pd, size=1.2) + theme_classic() + xlab("Atrazine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2AD6 2017")
cyp2ad6_dichloro_pdp <- autoplot(cyp2ad6_dichloro_pd, size=1.2) + theme_classic() + xlab("3,4-Dichlorophenyl isocyanate") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2AD6 2017")
cyp2ad6_metola_pdp <- autoplot(cyp2ad6_metola_pd, size=1.2) + theme_classic() + xlab("Metolachlor") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2AD6 2017")
cyp2ad6_carbamazepine_pdp <- autoplot(cyp2ad6_carbamazepine_pd, size=1.2) + theme_classic() + xlab("Carbamazepine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2AD6 2017")
cyp2ad6_choles_pdp <- autoplot(cyp2ad6_choles_pd, size=1.2) + theme_classic() + xlab("Cholesterol") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2AD6 2017")
cyp2ad6_fexo_pdp <- autoplot(cyp2ad6_fexo_pd, size=1.2) + theme_classic() + xlab("Fexofenadine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2AD6 2017")
cyp2ad6_desven_pdp <- autoplot(cyp2ad6_desven_pd, size=1.2) + theme_classic() + xlab("Desvenlafaxine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2AD6 2017")
cyp2ad6_lidocaine_pdp <- autoplot(cyp2ad6_lidocaine_pd, size=1.2) + theme_classic() + xlab("Lidocaine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2AD6 2017")
cyp2ad6_metformin_pdp <- autoplot(cyp2ad6_metformin_pd, size=1.2) + theme_classic() + xlab("Metformin") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2AD6 2017")
cyp2ad6_tramadol_pdp <- autoplot(cyp2ad6_tramadol_pd, size=1.2) + theme_classic() + xlab("Tramadol") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2AD6 2017")
cyp2ad6_deet_pdp <- autoplot(cyp2ad6_deet_pd, size=1.2) + theme_classic() + xlab("N,N-diethyl-meta-toluamide") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2AD6 2017")
cyp2ad6_venla_pdp <- autoplot(cyp2ad6_venla_pd, size=1.2) + theme_classic() + xlab("Venlafaxine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2AD6 2017")

#first plot#
intestine.xeno.p1 <- grid.arrange(
  cyp1a1_int_pdp_pyrene, cyp3a_int_pdp,
  cyp2ad6_dichloro_pdp, 
  cyp2ad6_metola_pdp, cyp2ad6_carbamazepine_pdp, cyp2ad6_choles_pdp, 
  cyp2ad6_fexo_pdp, cyp2ad6_desven_pdp, cyp2ad6_lidocaine_pdp, 
  cyp2ad6_metformin_pdp, cyp2ad6_tramadol_pdp, cyp2ad6_deet_pdp, 
  cyp2ad6_venla_pdp,ncol = 4)

ggsave("int.pd.pt1.jpeg", intestine.xeno.p1, height = 20, width = 20)


#CYP 2N13
cyp_2n13_2017_final <- cyp_2n13_2017 %>% dplyr::select(Effect,
                                                       Carbamazepine,Desvenlafaxine,  Fexofenadine,
                                                       Indole, Lidocaine, Metformin, `Methyl-1H-benzotriazole`,
                                                       Nicotine,Tramadol, `Tris(2-butoxyethyl)phosphate`,
                                                       Venlafaxine)
set.seed(3)
cf.final <- cforest(Effect~., data=cyp_2n13_2017_final, control=cforest_unbiased(mtry=4, ntree=5000))

cyp2n13_carbamazepine_pd <- partial(cf.final, pred.var="Carbamazepine", grid.resolution = 10)
cyp2n13_desvenla_pd <- partial(cf.final, pred.var="Venlafaxine", grid.resolution = 10)
cyp2n13_fexofen_pd <- partial(cf.final, pred.var="Fexofenadine", grid.resolution = 10)
cyp2n13_indole_pd <- partial(cf.final, pred.var="Indole", grid.resolution = 10)
cyp2n13_lidocaine_pd <- partial(cf.final, pred.var="Lidocaine", grid.resolution = 10)
cyp2n13_metformin_pd <- partial(cf.final, pred.var="Metformin", grid.resolution = 10)
cyp2n13_m1Hbt_pd <- partial(cf.final, pred.var="Methyl-1H-benzotriazole", grid.resolution = 10)
cyp2n13_nic_pd <- partial(cf.final, pred.var="Nicotine", grid.resolution = 10)
cyp2n13_tramadol_pd <- partial(cf.final, pred.var="Tramadol", grid.resolution = 10)
cyp2n13_t2bep_pd <- partial(cf.final, pred.var="Tris(2-butoxyethyl)phosphate", grid.resolution = 10)
cyp2n13_venla_pd <- partial(cf.final, pred.var="Desvenlafaxine", grid.resolution = 10)
cyp2n13_deet_pd <- partial(cf.final, pred.var="N,N-diethyl-meta-toluamide", grid.resolution = 10)

cyp2n13_carbamazepine_pdp <- autoplot(cyp2n13_carbamazepine_pd, size=1.2) + theme_classic() + xlab("Carbamazepine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2N13 2017")
cyp2n13_desvenla_pdp <- autoplot(cyp2n13_desvenla_pd, size=1.2) + theme_classic() + xlab("Desvenlafaxine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2N13 2017")
cyp2n13_fexofen_pdp <- autoplot(cyp2n13_fexofen_pd, size=1.2) + theme_classic() + xlab("Fexofenadine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2N13 2017")
cyp2n13_indole_pdp <- autoplot(cyp2n13_indole_pd, size=1.2) + theme_classic() + xlab("Indole") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2N13 2017")
cyp2n13_lidocaine_pdp <- autoplot(cyp2n13_lidocaine_pd, size=1.2) + theme_classic() + xlab("Lidocaine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2N13 2017")
cyp2n13_metformin_pdp <- autoplot(cyp2n13_metformin_pd, size=1.2) + theme_classic() + xlab("Metformin") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2N13 2017")
cyp2n13_m1Hbt_pdp <- autoplot(cyp2n13_m1Hbt_pd, size=1.2) + theme_classic() + xlab("Methyl-1H-benzotriazole") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2N13 2017")
cyp2n13_nic_pdp <- autoplot(cyp2n13_nic_pd, size=1.2) + theme_classic() + xlab("Nicotine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2N13 2017")
cyp2n13_tramadol_pdp <- autoplot(cyp2n13_tramadol_pd, size=1.2) + theme_classic() + xlab("Tramadol") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2N13 2017")
cyp2n13_t2bep_pdp <- autoplot(cyp2n13_t2bep_pd, size=1.2) + theme_classic() + xlab("Tris(2-butoxyethyl)phosphate") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2N13 2017")
cyp2n13_venla_pdp <- autoplot(cyp2n13_venla_pd, size=1.2) + theme_classic() + xlab("Venlafaxine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2N13 2017")
cyp2n13_deet_pdp <- autoplot(cyp2n13_deet_pd, size=1.2) + theme_classic() + xlab("N,N-diethyl-meta-toluamide") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("CYP 2N13 2017")

#UGT1A1
ugt_1a1_intestine_final <- ugt_1a1_intestine %>% dplyr::select(Effect, Carbamazepine,Cholesterol, Desvenlafaxine, 
                                                               Fexofenadine,Fluoranthene,Isophorone,
                                                               Lidocaine,Metformin, Methotrexate, "N,N-diethyl-meta-toluamide",
                                                               Triamterene,Sulfamethoxazole, 
                                                               Tramadol, 
                                                               Venlafaxine)

set.seed(3)
cf.final <- cforest(Effect~., data=ugt_1a1_intestine_final, control=cforest_unbiased(mtry=5, ntree=5000))

ugt1a1_int_carba_pd <- partial(cf.final, pred.var="Carbamazepine", grid.resolution = 10)
ugt1a1_int_cholesterol_pd <- partial(cf.final, pred.var="Cholesterol", grid.resolution = 10)
ugt1a1_int_desvenla_pd <- partial(cf.final, pred.var="Desvenlafaxine", grid.resolution = 10)
ugt1a1_int_fexo_pd <- partial(cf.final, pred.var="Fexofenadine", grid.resolution = 10)
ugt1a1_int_fluor_pd <- partial(cf.final, pred.var="Fluoranthene", grid.resolution = 10)
ugt1a1_int_isophorone_pd <- partial(cf.final, pred.var="Isophorone", grid.resolution = 10)
ugt1a1_int_lido_pd <- partial(cf.final, pred.var="Lidocaine", grid.resolution = 10)
ugt1a1_int_metfor_pd <- partial(cf.final, pred.var="Metformin", grid.resolution = 10)
ugt1a1_int_methotrex_pd <- partial(cf.final, pred.var="Methotrexate", grid.resolution = 10)
ugt1a1_int_deet_pd <- partial(cf.final, pred.var="N,N-diethyl-meta-toluamide", grid.resolution = 10)
ugt1a1_int_triam_pd <- partial(cf.final, pred.var="Triamterene", grid.resolution = 10)
ugt1a1_int_sulfa_pd <- partial(cf.final, pred.var="Sulfamethoxazole", grid.resolution = 10)
ugt1a1_int_tramadol_pd <- partial(cf.final, pred.var="Tramadol", grid.resolution = 10)
ugt1a1_int_t2bep_pd <- partial(cf.final, pred.var="Tris(2-butoxyethyl)phosphate", grid.resolution = 10)
ugt1a1_int_venla_pd <- partial(cf.final, pred.var="Venlafaxine", grid.resolution = 10)
ugt1a1_int_indole_pd <- partial(cf.final, pred.var="Indole", grid.resolution = 10)
ugt1a1_int_bap_pd <- partial(cf.final, pred.var="Benzo[a]pyrene", grid.resolution = 10)
ugt1a1_int_bpa_pd <- partial(cf.final, pred.var="Bisphenol A", grid.resolution = 10)
ugt1a1_int_34dpi_pd <- partial(cf.final, pred.var="3,4-Dichlorophenyl isocyanate", grid.resolution = 10)
ugt1a1_int_phen_pd <- partial(cf.final, pred.var="Phenanthrene", grid.resolution = 10)

ugt1a1_int_carba_pdp <- autoplot(ugt1a1_int_carba_pd, size=1.2) + theme_classic() + xlab("Carbamazepine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_cholesterol_pdp <- autoplot(ugt1a1_int_cholesterol_pd, size=1.2) + theme_classic() + xlab("Cholesterol") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_desvenla_pdp <- autoplot(ugt1a1_int_desvenla_pd, size=1.2) + theme_classic() + xlab("Desvenlafaxine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_fexo_pdp <- autoplot(ugt1a1_int_fexo_pd, size=1.2) + theme_classic() + xlab("Fexofenadine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_fluor_pdp <- autoplot(ugt1a1_int_fluor_pd, size=1.2) + theme_classic() + xlab("Fluoranthene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_isophorone_pdp <- autoplot(ugt1a1_int_isophorone_pd, size=1.2) + theme_classic() + xlab("Isophorone") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_lido_pdp <- autoplot(ugt1a1_int_lido_pd, size=1.2) + theme_classic() + xlab("Lidocaine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_metfor_pdp <- autoplot(ugt1a1_int_metfor_pd, size=1.2) + theme_classic() + xlab("Metformin") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_methotrex_pdp <- autoplot(ugt1a1_int_methotrex_pd, size=1.2) + theme_classic() + xlab("Methotrexate") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_deet_pdp <- autoplot(ugt1a1_int_deet_pd, size=1.2) + theme_classic() + xlab("N,N-diethyl-meta-toluamide") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_triam_pdp <- autoplot(ugt1a1_int_triam_pd, size=1.2) + theme_classic() + xlab("Triamterene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_sulfa_pdp <- autoplot(ugt1a1_int_sulfa_pd, size=1.2) + theme_classic() + xlab("Sulfamethoxazole") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_tramadol_pdp <- autoplot(ugt1a1_int_tramadol_pd, size=1.2) + theme_classic() + xlab("Tramadol") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_venla_pdp <- autoplot(ugt1a1_int_venla_pd, size=1.2) + theme_classic() + xlab("Venlafaxine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_t2bep_pdp <- autoplot(ugt1a1_int_t2bep_pd, size=1.2) + theme_classic() + xlab("Tris(2-butoxyethyl)phosphate") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_indole_pdp <- autoplot(ugt1a1_int_indole_pd, size=1.2) + theme_classic() + xlab("Indole") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_bap_pdp <- autoplot(ugt1a1_int_bap_pd, size=1.2) + theme_classic() + xlab("Benzo[a]pyrene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_bpa_pdp <- autoplot(ugt1a1_int_bpa_pd, size=1.2) + theme_classic() + xlab("Bisphenol A") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_34dpi_pdp <- autoplot(ugt1a1_int_34dpi_pd, size=1.2) + theme_classic() + xlab("3,4-Dichlorophenyl isocyanate") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")
ugt1a1_int_phen_pdp <- autoplot(ugt1a1_int_phen_pd, size=1.2) + theme_classic() + xlab("Phenanthrene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("UGT 1A1")

intestine.xeno.p2 <- grid.arrange(cyp2n13_carbamazepine_pdp, cyp2n13_desvenla_pdp, cyp2n13_fexofen_pdp, 
                                  cyp2n13_indole_pdp, cyp2n13_lidocaine_pdp, cyp2n13_metformin_pdp, 
                                  cyp2n13_m1Hbt_pdp, cyp2n13_nic_pdp, cyp2n13_tramadol_pdp, 
                                  cyp2n13_t2bep_pdp, cyp2n13_venla_pdp, cyp2n13_deet_pdp, ugt1a1_int_carba_pdp,
                                  ugt1a1_int_cholesterol_pdp, ugt1a1_int_desvenla_pdp, ugt1a1_int_fexo_pdp,
                                  ugt1a1_int_fluor_pdp, ugt1a1_int_isophorone_pdp, ugt1a1_int_lido_pdp,
                                  ugt1a1_int_metfor_pdp, ugt1a1_int_methotrex_pdp, ugt1a1_int_deet_pdp, 
                                  ugt1a1_int_triam_pdp, ugt1a1_int_sulfa_pdp, ugt1a1_int_tramadol_pdp, 
                                  ugt1a1_int_venla_pdp, ugt1a1_int_t2bep_pdp,ugt1a1_int_indole_pdp,ugt1a1_int_bap_pdp,
                                  ugt1a1_int_bpa_pdp, ugt1a1_int_34dpi_pdp, ugt1a1_int_phen_pdp,
                                  ncol = 4)
ggsave("int.pd.pt2.jpeg", intestine.xeno.p2, height = 20, width = 20)

beep(6)

#xenobiotic - in vitro ####
#AHR
ahr_final <- ahr %>% dplyr::select(Effect,"beta-Sitosterol", Acetaminophen, Camphor,
                                   Fluoranthene, Phenanthrene, Pyrene, `Benzo[a]pyrene`, Anthraquinone, 
                                   Metformin)

set.seed(3)
cf.final <- cforest(Effect~., data=ahr_final, control=cforest_unbiased(mtry=3, ntree=5000))

ahR_anthra_pd <- partial(cf.final, pred.var="Anthraquinone", grid.resolution = 10)
ahR_acetaminophen_pd <- partial(cf.final, pred.var="Acetaminophen", grid.resolution = 10)
ahR_betasito_pd <- partial(cf.final, pred.var="beta-Sitosterol", grid.resolution = 10)
ahR_fluoranthene_pd <- partial(cf.final, pred.var="Fluoranthene", grid.resolution = 10)
ahR_phenan_pd <- partial(cf.final, pred.var="Phenanthrene", grid.resolution = 10)
ahR_pyrene_pd <- partial(cf.final, pred.var="Pyrene", grid.resolution = 10)

ahR_anthra_pdp <- autoplot(ahR_anthra_pd, size=1.2) + theme_classic() + xlab("Anthraquinone") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("ahR_cis")
ahR_acetaminophen_pdp <- autoplot(ahR_acetaminophen_pd, size=1.2) + theme_classic() + xlab("Acetaminophen") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("ahR_cis")
ahR_betasito_pdp <- autoplot(ahR_betasito_pd, size=1.2) + theme_classic() + xlab("beta-Sitosterol") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("ahR_cis")
ahR_fluoranthene_pdp <- autoplot(ahR_fluoranthene_pd, size=1.2) + theme_classic() + xlab("Fluoranthene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("ahR_cis")
ahR_phenan_pdp <- autoplot(ahR_phenan_pd, size=1.2) + theme_classic() + xlab("Phenanthrene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("ahR_cis")
ahR_pyrene_pdp <- autoplot(ahR_pyrene_pd, size=1.2) + theme_classic() + xlab("Pyrene") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("ahR_cis")

#PXR_CIS
PXR_cis_final <- PXR_cis %>% dplyr::select(Effect, "beta-Sitosterol")
set.seed(3)
cf.final <- cforest(Effect~., data=PXR_cis_final, control=cforest_unbiased(mtry=1, ntree=5000))

pxrcis_bs_pd <- partial(cf.final, pred.var="beta-Sitosterol", grid.resolution = 10)

pxrcis_bs_pdp <- autoplot(pxrcis_bs_pd, size=1.2) + theme_classic() + xlab("beta-Sitosterol") + ylab("Effect") +
  theme(text=element_text(size=20)) + ggtitle("PXR_cis")

#PXR_Trans
PXR_trans_final <- PXR_trans %>% dplyr::select(Effect, Cotinine, Nicotine, Caffeine)
set.seed(3)
cf.final <- cforest(Effect~., data=PXR_trans_final, control=cforest_unbiased(mtry=1, ntree=5000))

pxrtrans_cot_pd <- partial(cf.final, pred.var="Cotinine", grid.resolution = 10)
pxrtrans_cot_pdp <- autoplot(pxrtrans_cot_pd, size=1.2) + theme_classic() + xlab("Cotinine") + ylab("Effect") +
  theme(text=element_text(size=20)) + ggtitle("PXR_trans")
pxrtrans_nic_pd <- partial(cf.final, pred.var="Nicotine", grid.resolution = 10)
pxrtrans_nic_pdp <- autoplot(pxrtrans_nic_pd, size=1.2) + theme_classic() + xlab("Nicotine") + ylab("Effect") +
  theme(text=element_text(size=20)) + ggtitle("PXR_trans")
pxrtrans_caf_pd <- partial(cf.final, pred.var="Caffeine", grid.resolution = 10)
pxrtrans_caf_pdp <- autoplot(pxrtrans_caf_pd, size=1.2) + theme_classic() + xlab("Caffeine") + ylab("Effect") +
  theme(text=element_text(size=20)) + ggtitle("PXR_trans")

#PPARg
PPARg_final <- PPARg %>% dplyr::select(Effect,Cotinine, Anthraquinone)
set.seed(3)
cf.final <- cforest(Effect~., data=PPARg_final, control=cforest_unbiased(mtry=1, ntree=5000))

pparg_ccot_pd <- partial(cf.final, pred.var="Cotinine", grid.resolution = 10)
pparg_anthra_pd <- partial(cf.final, pred.var="Anthraquinone", grid.resolution = 10)

pparg_ccot_pdp <- autoplot(pparg_ccot_pd, size=1.2) + theme_classic() + xlab("Cotinine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("PPARg_trans")
pparg_anthra_pdp <- autoplot(pparg_anthra_pd, size=1.2) + theme_classic() + xlab("Anthraquinone") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("PPARg_trans")

#GR
GR_final <- GR %>% dplyr::select(Effect,Metformin)

set.seed(3)
cf.final <- cforest(Effect~., data=GR_final, control=cforest_unbiased(mtry=1, ntree=5000))

GR_met_pd <- partial(cf.final, pred.var = "Metformin", grid.resolution = 10)
GR_met_pdp <- autoplot(GR_met_pd, size=1.2) + theme_classic() + xlab("Metformin") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("GR")

#ARE
ARE_final <- ARE %>% dplyr::select(Effect,Cotinine, Anthraquinone, Carbazole)

set.seed(3)
cf.final <- cforest(Effect~., data=ARE_final, control=cforest_unbiased(mtry=1, ntree=5000))

ARE_cot_pd <- partial(cf.final, pred.var = "Cotinine", grid.resolution = 10)
ARE_anth_pd <- partial(cf.final, pred.var = "Anthraquinone", grid.resolution = 10)
ARE_carb_pd <- partial(cf.final, pred.var = "Carbazole", grid.resolution = 10)

ARE_cot_pdp <- autoplot(ARE_cot_pd, size=1.2) + theme_classic() + xlab("Cotinine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("ARE")
ARE_anth_pdp <- autoplot(ARE_anth_pd, size=1.2) + theme_classic() + xlab("Anthraquinone") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("ARE")
ARE_carb_pdp <- autoplot(ARE_carb_pd, size=1.2) + theme_classic() + xlab("Carbazole") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("ARE")

#PPARa
PPARa_final <- PPARa %>% dplyr::select(Effect,Cotinine)

set.seed(3)
cf.final <- cforest(Effect~., data=PPARa_final, control=cforest_unbiased(mtry=1, ntree=5000))
PPARa_pd <- partial(cf.final, pred.var = "Cotinine", grid.resolution = 10)
PPARa_pdp <- autoplot(PPARa_pd, size=1.2) + theme_classic() + xlab("Cotinine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("PPARa")

#PPRE
PPRE_final <- PPRE %>% dplyr::select(Effect,Cotinine)

set.seed(3)
cf.final <- cforest(Effect~., data=PPRE_final, control=cforest_unbiased(mtry=1, ntree=5000))
PPRE_pd <- partial(cf.final, pred.var = "Cotinine", grid.resolution = 10)
PPRE_pdp <- autoplot(PPRE_pd, size=1.2) + theme_classic() + xlab("Cotinine") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("PPRE")

#RXRb
RXRb_final <- RXRb %>% dplyr::select(Effect,"beta-Sitosterol")

set.seed(3)
cf.final <- cforest(Effect~., data=RXRb_final, control=cforest_unbiased(mtry=1, ntree=5000))
RXRb_pd <- partial(cf.final, pred.var = "beta-Sitosterol", grid.resolution = 10)
RXRb_pdp <- autoplot(RXRb_pd, size=1.2) + theme_classic() + xlab("beta-Sitosterol") + ylab("Effect") +
  theme(text=element_text(size=20))+ ggtitle("RXRb")


invitro.xeno <-grid.arrange(ahR_anthra_pdp, ahR_acetaminophen_pdp, ahR_betasito_pdp,
                            ahR_fluoranthene_pdp, ahR_phenan_pdp,ahR_pyrene_pdp,
                            pxrcis_bs_pdp,
                            pxrtrans_cot_pdp, pparg_ccot_pdp, pparg_anthra_pdp, 
                            GR_met_pdp, ARE_cot_pdp, ARE_anth_pdp, ARE_carb_pdp, 
                            PPARa_pdp,PPRE_pdp,RXRb_pdp, ncol = 4)

ggsave("invitro_pdp.jpeg", invitro.xeno, height = 20, width = 20)


#final OUTPUT####
names(chem.2017)
list(unique(chem.2017$Detect.code))
chem.2017 <- read_excel("C:\\Users\\erinm\\OneDrive\\Desktop\\GLRI Project\\Milwauke\\Data for Papier\\Chemistry\\Compiled_Chemistry\\Chemistry Compiled_Final.xlsx", "2017") %>% 
  filter(Media == "Water", !Site %in% c("UWM", "MIM-BK"))  %>% filter(!Detect.code %in% ("<")) %>%
  select(CAS, Chemical)
chem.2018 <- read_excel("C:\\Users\\erinm\\OneDrive\\Desktop\\GLRI Project\\Milwauke\\Data for Papier\\Chemistry\\Compiled_Chemistry\\Chemistry Compiled_Final.xlsx", "2018")%>%
  filter(Media == "Water", !Site %in% c("UWM", "MIM-BK")) %>% filter(!Detect.code %in% ("<")) %>%
  select(CAS, Chemical)

chemistry_whole <- bind_rows(chem.2017, chem.2018) %>% distinct()
View(chemistry_whole)

##make heat map with covariance ####

final.RF <- read_excel("C:\\Users\\erinm\\OneDrive\\Desktop\\GLRI Project\\Milwauke\\Data for Papier\\Prioritization\\Random Forest\\Random Forest Output 2022.18.03.xlsx") %>% filter(`Important Variables` != "NA")
View(final.RF)
list(unique(final.RF$Endpoint))
final.RF$Endpoint_Year <- paste(final.RF$Endpoint, final.RF$Year)
final.RF$Category <- ifelse(final.RF$Endpoint %in% c("ahR_cis", "CYP1A1_intestine", "CYP1A1_liver",
                                                     "CYP2AD6_intestine", "CYP2N13_intestine",
                                                     "CYP3A_intestine", "CYP3A_liver", "PPARg", "PXR_cis",
                                                     "PXR_trans", "UGT1A1_intestine", 
                                                     "UGT1A1_liver", "GR", "ARE", "PPARa", "PPRE", "RXRb"), "Xenobiotic Response", 
                            ifelse(final.RF$Endpoint %in% c("Era_trans", "ERE_cis", "RIA",
                                                            "RIA_F", "T47"), "Endocrine",
                                   "Misc"))

list(unique(final.RF$Category))

final.RF_1 <- final.RF %>% rename("Chemical" = "Important Variables") %>% select(Endpoint_Year, Category, Chemical)

chem_RF <- left_join(chemistry_whole, final.RF_1) %>% group_by(CAS, Chemical, Category) %>% 
  summarize(n_eff = n_distinct(Endpoint_Year))
chem_RF$n_eff <- ifelse(is.na(chem_RF$Category), 0, chem_RF$n_eff)
View(chem_RF)

chem_RF_1 <- chem_RF %>% spread(key = "Category", value = "n_eff") %>% select(-"<NA>")
chem_RF_1[is.na(chem_RF_1)] <- 0

chem_RF_2 <- chem_RF_1 %>% rename("nER" = "Endocrine", "nXR" = "Xenobiotic Response")
chem_RF_2$nER_cat <- 5
chem_RF_2$nXR_cat <- 17

chem_RF_2$Freq_ER <- chem_RF_2$nER / chem_RF_2$nER_cat
chem_RF_2$Freq_XR <- chem_RF_2$nXR / chem_RF_2$nXR_cat

chem_RF_2$PS_effect_ER <- ifelse(chem_RF_2$Freq_ER == 0, 0,
                                 ifelse(chem_RF_2$Freq_ER > 0 & chem_RF_2$Freq_ER < 0.5, 1.25,
                                        ifelse(chem_RF_2$Freq_ER >= 0.5, 2.5, 100)))

chem_RF_2$PS_effect_XR <- ifelse(chem_RF_2$Freq_XR == 0, 0,
                                 ifelse(chem_RF_2$Freq_XR > 0 & chem_RF_2$Freq_XR < 0.5, 1.25,
                                        ifelse(chem_RF_2$Freq_XR >= 0.5, 2.5, 100)))

View(chem_RF_2)

write_xlsx(chem_RF_2, "RF_output_for_SI.xlsx")

#create a heat map
library(superheat)
library(viridisLite)

names(final.RF)
final.RF_1 <- final.RF %>% rename("Chemical" = "Important Variables") %>% select(Endpoint_Year, Category, Chemical, Endpoint_Year)

chem_RF_for_Fig <- left_join(chemistry_whole, final.RF_1)

chem_RF_for_Fig$indicator <- ifelse(is.na(chem_RF_for_Fig$Endpoint_Year), 0, 1)
list(unique(chem_RF_for_Fig$Endpoint_Year))

chem_RF_for_Fig_1 <- chem_RF_for_Fig %>% select(-Category) %>% spread(key = "Endpoint_Year", value = "indicator") %>%
  select(-"<NA>", -CAS) %>% relocate("T47 2017+2018", .before = "ahR_cis 2017+2018") %>%
  relocate("RIA 2017", .after = "T47 2017+2018") %>% relocate("RIA_F 2017", .after = "RIA 2017") %>%
  relocate("Era_trans 2017+2018", .after = "RIA_F 2017") %>% relocate("ERE_cis 2017+2018", .after = "Era_trans 2017+2018") %>%
  relocate("ahR_cis 2017+2018", .before = "PPARg 2017+2018") %>% relocate("ARE 2017+2018", .before = "ahR_cis 2017+2018") %>%
  relocate("GR 2017+2018", .after = "ahR_cis 2017+2018") %>% relocate("PPARa 2017+2018", .before = "PPARg 2017+2018") %>%
  relocate("UGT1A1_intestine 2017", .after = "CYP3A_intestine 2017") %>% relocate("CYP3A_liver 2017", .after = "CYP3A_intestine 2017") %>%
  relocate("UGT1A1_liver 2017", .after = "UGT1A1_intestine 2017") %>%
  rename("E2-EQ" = "T47 2017+2018", "E2_M" = "RIA 2017", "E2_F" = "RIA_F 2017", 
         "ERa_trans" = "Era_trans 2017+2018", "ERE_cis" = "ERE_cis 2017+2018", 
         "ahR_cis" = "ahR_cis 2017+2018", "PPARg_trans" = "PPARg 2017+2018", "PXR_cis" = "PXR_cis 2017+2018",
         "PXR_trans" = "PXR_trans 2017+2018", "ARE_cis" = "ARE 2017+2018", "GR_trans" = "GR 2017+2018", 
         "PPARa_trans"="PPARa 2017+2018", "PPRE_cis"="PPRE 2017+2018", "RXRb_trans" = "RXRb 2017+2018")

names(chem_RF_for_Fig_1)
list(unique(chem_RF_for_Fig_1$Chemical))

chem_RF_for_Fig_1[is.na(chem_RF_for_Fig_1)]<- 0

list(unique(chem_RF_for_Fig_1$Chemical))
chem_RF_for_Fig_1$Chemical <- gsub("chem_RF_for_Fig_1$Chemical", "Galaxolide", chem_RF_for_Fig_1$Chemical)

chem_RF_for_Fig_2 <- chem_RF_for_Fig_1 %>% column_to_rownames("Chemical") 

chem_RF_for_Fig_2 <- as.matrix(chem_RF_for_Fig_2)

cov.all <- superheat(X = chem_RF_for_Fig_2,
          scale = FALSE,
          pretty.order.rows = FALSE,
          pretty.order.cols = FALSE,
          force.grid.hline = TRUE,
          col.dendrogram = F,  #clustering
          row.dendrogram = F,  #clustering
          grid.hline.col = "darkgrey",
          grid.vline.col = "darkgrey",
          left.label.col = 'white',
          bottom.label.col = 'white',
          left.label.text.col = 'black',
          bottom.label.text.col = 'black',
          heat.pal=c("white", "black"),
          bottom.label.text.angle = 90,
          legend = FALSE,
          row.title = "Chemical",
           column.title = "Site-Specific Effect",
          row.title.size = 8,
          column.title.size = 8,
          bottom.label.text.size =  12, left.label.text.size = 10)


ggsave("COV_Final.jpeg",cov.all, height = 35, width = 20)

